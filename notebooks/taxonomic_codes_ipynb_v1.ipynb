{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNHSLyjRlf7sYEKJ2Yplm41",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RobBurnap/Bioinformatics-MICR4203-MICR5203/blob/main/notebooks/taxonomic_codes_ipynb_v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Developing a taxonomic table for taxonomic codes for a diverse set of sequences**"
      ],
      "metadata": {
        "id": "afZn240E8-8I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "BIOINFO4/5203 ‚Äî Colab Exercise Template\n",
        "\n",
        "Use this template for every weekly exercise. It standardizes setup, data paths, and the final summary so grading in Canvas is quick.\n",
        "\n",
        "Workflow\n",
        "\n",
        "    Click the \"Open in Colab\" link in Canvas (points to this notebook in GitHub).\n",
        "    Run Setup cells (installs and mounts Google Drive).\n",
        "    Run the Exercise cells (edit as instructed for each lecture).\n",
        "    Verify the Results Summary prints the values requested by Canvas.\n",
        "    File ‚Üí Print ‚Üí Save as PDF and upload .ipynb + PDF to Canvas.\n",
        "\n",
        "    Instructor note (delete in student copy if desired):\n",
        "\n",
        "        Place datasets for this lecture at: Drive ‚Üí BIOINFO4-5203-F25 ‚Üí Data ‚Üí Lxx_topic\n",
        "        Update the constants in Config below: COURSE_DIR, LECTURE_CODE (e.g., L05), and TOPIC.\n",
        "        For heavy jobs (trees, assemblies), provide the PETE output files in the same Data folder so students can analyze them here if the queue is busy.\n",
        "\n"
      ],
      "metadata": {
        "id": "frmCc0lAQcYQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Auto‚Äësetup + course folder (uses your Teaching path)**"
      ],
      "metadata": {
        "id": "bw0BsPOEGVL3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##A. Mount Google Drive, Import Coding Libraries Necessary for Running Subsequent Code"
      ],
      "metadata": {
        "id": "6JW7liKMC3H-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Install FIRST, then import\n",
        "%pip install -q biopython       # Install the Biopython package quietly (-q suppresses most output) so we can work with biological sequence files\n",
        "\n",
        "from google.colab import drive  # Import the module that lets Colab interact with Google Drive\n",
        "drive.mount('/content/drive')   # Mount your Google Drive so it appears in Colab's file system under /content/drive\n",
        "\n",
        "import os, pandas as pd          # Import 'os' for file/directory operations, and pandas for working with data tables\n",
        "from Bio import SeqIO            # Import SeqIO from Biopython for reading/writing biological sequence files (FASTA, GenBank, etc.)\n",
        "import matplotlib.pyplot as plt  # Import Matplotlib's plotting library to create figures and graphs\n",
        "\n",
        "print(\"‚úÖ Dependencies installed & Drive mounted.\")\n"
      ],
      "metadata": {
        "id": "N1NrV2YaGfZ_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a27bde1-ebe2-426a-b242-54ed1e5602d7"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hMounted at /content/drive\n",
            "‚úÖ Dependencies installed & Drive mounted.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## B. Course folders: Define the course folders for places to load data to be processed and output to be saved\n",
        "\n",
        "Edit only `LECTURE_CODE` and `TOPIC` if needed. All inputs will live in `Data/LECTURE_TOPIC` and outputs in `Outputs/LECTURE_TOPIC`."
      ],
      "metadata": {
        "id": "j7uJVzrKC-8v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2) Define file sturcture"
      ],
      "metadata": {
        "id": "onPHWY4dGku-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# --- Course folder config (customize LECTURE_CODE/TOPIC only) ---\n",
        "COURSE_DIR   = \"/content/drive/MyDrive/Teaching/BIOINFO4-5203-F25\"\n",
        "LECTURE_CODE = \"Taxonomy\"            # change per week (e.g., L02, L03, ...)\n",
        "TOPIC        = \"Template\"    # short slug for the exercise\n",
        "\n",
        "# Derived paths (do not change)\n",
        "DATA_DIR   = f\"{COURSE_DIR}/Data/{LECTURE_CODE}_{TOPIC}\"\n",
        "OUTPUT_DIR = f\"{COURSE_DIR}/Outputs/{LECTURE_CODE}_{TOPIC}\"\n",
        "\n",
        "# Create folder structure if missing\n",
        "for p in [f\"{COURSE_DIR}/Data\", f\"{COURSE_DIR}/Outputs\", f\"{COURSE_DIR}/Notebooks\", DATA_DIR, OUTPUT_DIR]:\n",
        "    os.makedirs(p, exist_ok=True)\n",
        "\n",
        "print(\"üìÅ COURSE_DIR :\", COURSE_DIR)\n",
        "print(\"üìÅ DATA_DIR   :\", DATA_DIR)\n",
        "print(\"üìÅ OUTPUT_DIR :\", OUTPUT_DIR)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C1wyBalSGox_",
        "outputId": "5a48421d-ddfe-4d71-c217-9b55c7f38d4c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÅ COURSE_DIR : /content/drive/MyDrive/Teaching/BIOINFO4-5203-F25\n",
            "üìÅ DATA_DIR   : /content/drive/MyDrive/Teaching/BIOINFO4-5203-F25/Data/Taxonomy_Template\n",
            "üìÅ OUTPUT_DIR : /content/drive/MyDrive/Teaching/BIOINFO4-5203-F25/Outputs/Taxonomy_Template\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Take file name \"taxonomic_cmmon_names\" and find taxonomic ids"
      ],
      "metadata": {
        "id": "H1Qe2LFAFz5A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3) Version 3 Aug 25"
      ],
      "metadata": {
        "id": "ccijET3tGsBf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Build panel from your full names file & write CSV + TXT outputs (with eukaryote subgroup + common name) ---\n",
        "from Bio import Entrez\n",
        "from pathlib import Path\n",
        "import pandas as pd, io, re, os, sys, time\n",
        "\n",
        "# REQUIRED\n",
        "Entrez.email = \"you@university.edu\"\n",
        "# Entrez.api_key = \"YOUR_NCBI_API_KEY\"  # optional\n",
        "\n",
        "assert 'DATA_DIR' in globals() and 'OUTPUT_DIR' in globals(), \"Run your course folder setup cell first.\"\n",
        "DATA_DIR = Path(DATA_DIR); OUT = Path(OUTPUT_DIR)\n",
        "OUT.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Locate the master names file\n",
        "CANDIDATES = [\n",
        "    DATA_DIR / \"taxonomic_common_names\",\n",
        "    DATA_DIR / \"taxonomic_common_names.txt\",\n",
        "    DATA_DIR / \"taxonomic_common_names.csv\",\n",
        "    DATA_DIR / \"taxonomic_common_names.tsv\",\n",
        "]\n",
        "NAMES_PATH = next((p for p in CANDIDATES if p.exists()), None)\n",
        "if not NAMES_PATH:\n",
        "    raise FileNotFoundError(\n",
        "        f\"Could not find 'taxonomic_cmmon_names' (txt/csv/tsv) in {DATA_DIR}.\\n\"\n",
        "        \"Create it with one name per line (scientific or common).\"\n",
        "    )\n",
        "print(\"üìÑ Names file:\", NAMES_PATH)\n",
        "\n",
        "def load_names(path: Path):\n",
        "    text = path.read_text(errors=\"ignore\")\n",
        "    head = \"\\n\".join(text.splitlines()[:5])\n",
        "    is_table = (\",\" in head) or (\"\\t\" in head)\n",
        "    names = []\n",
        "    if is_table:\n",
        "        sep = \"\\t\" if \"\\t\" in head else \",\"\n",
        "        df = pd.read_csv(io.StringIO(text), sep=sep, comment=\"#\", header=None)\n",
        "        names = [str(x).strip() for x in df.iloc[:,0].tolist() if str(x).strip()]\n",
        "    else:\n",
        "        for line in text.splitlines():\n",
        "            line = line.strip()\n",
        "            if line and not line.startswith(\"#\"):\n",
        "                names.append(line)\n",
        "    return names\n",
        "\n",
        "raw_names = load_names(NAMES_PATH)\n",
        "print(f\"üìù Loaded {len(raw_names)} name(s)\")\n",
        "\n",
        "def fetch_taxnode_by_id(tid: str):\n",
        "    h2 = Entrez.efetch(db=\"taxonomy\", id=tid, retmode=\"xml\")\n",
        "    rec = Entrez.read(h2); h2.close()\n",
        "    return rec[0] if rec else {}\n",
        "\n",
        "def extract_common_name(node: dict) -> str:\n",
        "    # Try common name fields if present\n",
        "    cn = node.get(\"CommonName\") or node.get(\"GenbankCommonName\")\n",
        "    if cn: return cn\n",
        "    other = node.get(\"OtherNames\") or {}\n",
        "    for k in (\"GenbankCommonName\",\"CommonName\"):\n",
        "        if other.get(k): return other[k]\n",
        "    # Fall back to first 'Name' of type 'genbank common name'\n",
        "    syns = other.get(\"Synonym\") or []\n",
        "    return \"\"\n",
        "\n",
        "def infer_superkingdom(node: dict) -> str:\n",
        "    return next((x[\"ScientificName\"] for x in node.get(\"LineageEx\", [])\n",
        "                 if x.get(\"Rank\") == \"superkingdom\"), \"NA\")\n",
        "\n",
        "def infer_euk_group(node: dict) -> str:\n",
        "    \"\"\"\n",
        "    Coarse eukaryote grouping for teaching:\n",
        "      Mammal, Bird/Reptile/Fish, Plant, Fungi, Protist\n",
        "    Non-eukaryotes -> ''\n",
        "    \"\"\"\n",
        "    lineage = [x[\"ScientificName\"] for x in node.get(\"LineageEx\", [])]\n",
        "    lineage_set = set(s.lower() for s in lineage)\n",
        "\n",
        "    if \"eukaryota\" not in lineage_set:\n",
        "        return \"\"\n",
        "\n",
        "    # Animals (Metazoa)\n",
        "    if \"metazoa\" in lineage_set:\n",
        "        # Vertebrates and subclades ‚Üí mammals, birds, reptiles, fish lumped\n",
        "        verte_keys = {\"vertebrata\", \"gnathostomata\", \"tetrapoda\", \"mammalia\", \"aves\", \"reptilia\", \"actinopterygii\"}\n",
        "        if any(k in lineage_set for k in verte_keys):\n",
        "            # Make mammals explicit when possible\n",
        "            if \"mammalia\" in lineage_set:\n",
        "                return \"Mammal\"\n",
        "            return \"Bird/Reptile/Fish\"\n",
        "        return \"Protist\"  # non-vertebrate animals (rare in this list) could be left as \"Protist\" bucket or \"Metazoa\"\n",
        "\n",
        "    # Plants\n",
        "    if \"viridiplantae\" in lineage_set or \"streptophyta\" in lineage_set or \"embryophyta\" in lineage_set:\n",
        "        return \"Plant\"\n",
        "\n",
        "    # Fungi\n",
        "    if \"fungi\" in lineage_set:\n",
        "        return \"Fungi\"\n",
        "\n",
        "    # Large protist lineages\n",
        "    protist_keys = {\n",
        "        \"amoebozoa\",\"sar\",\"stramenopiles\",\"alveolata\",\"rhizaria\",\"discoba\",\"excavata\",\n",
        "        \"haptophyta\",\"cryptophyta\",\"choanoflagellida\",\"euglenozoa\",\"apicomplexa\",\"ciliophora\"\n",
        "    }\n",
        "    if any(k in lineage_set for k in protist_keys):\n",
        "        return \"Protist\"\n",
        "\n",
        "    return \"Protist\"  # default for eukaryotes we didn‚Äôt categorize above\n",
        "\n",
        "def tax_lookup(name: str):\n",
        "    \"\"\"\n",
        "    Resolve 'name' ‚Üí (taxid, canonical, rank, superkingdom, euk_group, common_name, match_type, status)\n",
        "    \"\"\"\n",
        "    name = name.strip()\n",
        "\n",
        "    # Direct TaxID\n",
        "    if re.fullmatch(r\"\\d+\", name):\n",
        "        try:\n",
        "            node = fetch_taxnode_by_id(name)\n",
        "            return (int(name),\n",
        "                    node.get(\"ScientificName\",\"\"),\n",
        "                    node.get(\"Rank\",\"\"),\n",
        "                    infer_superkingdom(node),\n",
        "                    infer_euk_group(node),\n",
        "                    extract_common_name(node),\n",
        "                    \"TAXID\", \"ok\")\n",
        "        except Exception as e:\n",
        "            return \"\", \"\", \"\", \"NA\", \"\", \"\", \"TAXID\", f\"efetch_failed:{e}\"\n",
        "\n",
        "    queries = [\n",
        "        (f\"\\\"{name}\\\"[SCIN]\", \"SCIN\"),\n",
        "        (f\"\\\"{name}\\\"[Common Name]\", \"COMMON\"),\n",
        "        (name, \"LOOSE\"),\n",
        "    ]\n",
        "    for q, tag in queries:\n",
        "        try:\n",
        "            h = Entrez.esearch(db=\"taxonomy\", term=q, retmode=\"xml\"); r = Entrez.read(h); h.close()\n",
        "            if int(r[\"Count\"]) == 0:\n",
        "                continue\n",
        "            tid = r[\"IdList\"][0]\n",
        "            node = fetch_taxnode_by_id(tid)\n",
        "            return (int(tid),\n",
        "                    node.get(\"ScientificName\",\"\"),\n",
        "                    node.get(\"Rank\",\"\"),\n",
        "                    infer_superkingdom(node),\n",
        "                    infer_euk_group(node),\n",
        "                    extract_common_name(node),\n",
        "                    tag, \"ok\")\n",
        "        except Exception as e:\n",
        "            sys.stderr.write(f\"[warn] lookup '{name}' via {tag}: {e}\\n\")\n",
        "            time.sleep(0.15)\n",
        "            continue\n",
        "    return \"\", \"\", \"\", \"NA\", \"\", \"\", \"NA\", \"no_match\"\n",
        "\n",
        "rows = []\n",
        "seen = set()\n",
        "for nm in raw_names:\n",
        "    key = nm.strip().lower()\n",
        "    if not key or key in seen:\n",
        "        continue\n",
        "    seen.add(key)\n",
        "    tid, canon, rank, dom, egrp, common, tag, status = tax_lookup(nm)\n",
        "    rows.append({\n",
        "        \"input_name\": nm,\n",
        "        \"taxid\": tid,\n",
        "        \"canonical_name\": canon,\n",
        "        \"common_name\": common,\n",
        "        \"rank\": rank,\n",
        "        \"superkingdom\": dom,     # Bacteria / Archaea / Eukaryota\n",
        "        \"euk_group\": egrp,       # Mammal / Bird/Reptile/Fish / Plant / Fungi / Protist / ''\n",
        "        \"match_type\": tag,\n",
        "        \"status\": status\n",
        "    })\n",
        "    time.sleep(0.25)\n",
        "\n",
        "df = pd.DataFrame(rows).sort_values(\n",
        "    [\"status\",\"superkingdom\",\"euk_group\",\"canonical_name\",\"input_name\"],\n",
        "    na_position=\"last\"\n",
        ").reset_index(drop=True)\n",
        "\n",
        "# Write outputs\n",
        "map_csv   = OUT / \"taxon_map.csv\"\n",
        "ids_txt   = OUT / \"taxids_list.txt\"\n",
        "entrez_txt= OUT / \"entrez_query.txt\"\n",
        "\n",
        "df.to_csv(map_csv, index=False)\n",
        "valid_taxids = [str(t) for t in df[\"taxid\"].tolist() if str(t).isdigit()]\n",
        "ids_txt.write_text(\"\\n\".join(valid_taxids))\n",
        "entrez_txt.write_text(\" OR \".join([f\"txid{t}[ORGN]\" for t in valid_taxids]))\n",
        "\n",
        "print(\"üó∫  Map CSV :\", map_csv)\n",
        "print(\"üß¨ TaxIDs  :\", ids_txt)\n",
        "print(\"üîé ENTREQ  :\", entrez_txt)\n",
        "\n",
        "print(\"\\n=== Summary ===\")\n",
        "print(\"Total names read :\", len(raw_names))\n",
        "print(\"Resolved (ok)    :\", (df[\"status\"]==\"ok\").sum())\n",
        "print(\"Unresolved       :\", (df[\"status\"]!=\"ok\").sum())\n",
        "if (df[\"status\"]!=\"ok\").any():\n",
        "    display(df[df[\"status\"]!=\"ok\"][[\"input_name\",\"status\"]].head(12))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        },
        "id": "H2dejbPgSSSg",
        "outputId": "9d6855f8-4dc0-417e-ccb4-e7a76575acd8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÑ Names file: /content/drive/MyDrive/Teaching/BIOINFO4-5203-F25/Data/Taxonomy_Template/taxonomic_common_names.txt\n",
            "üìù Loaded 127 name(s)\n",
            "üó∫  Map CSV : /content/drive/MyDrive/Teaching/BIOINFO4-5203-F25/Outputs/Taxonomy_Template/taxon_map.csv\n",
            "üß¨ TaxIDs  : /content/drive/MyDrive/Teaching/BIOINFO4-5203-F25/Outputs/Taxonomy_Template/taxids_list.txt\n",
            "üîé ENTREQ  : /content/drive/MyDrive/Teaching/BIOINFO4-5203-F25/Outputs/Taxonomy_Template/entrez_query.txt\n",
            "\n",
            "=== Summary ===\n",
            "Total names read : 127\n",
            "Resolved (ok)    : 123\n",
            "Unresolved       : 1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                  input_name    status\n",
              "0  Candidatus Syntrophoarchaeum butanivorans  no_match"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5ec6e0cb-9fea-4d25-a5f0-cd2b0ba5009c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>input_name</th>\n",
              "      <th>status</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Candidatus Syntrophoarchaeum butanivorans</td>\n",
              "      <td>no_match</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5ec6e0cb-9fea-4d25-a5f0-cd2b0ba5009c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5ec6e0cb-9fea-4d25-a5f0-cd2b0ba5009c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5ec6e0cb-9fea-4d25-a5f0-cd2b0ba5009c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"    display(df[df[\\\"status\\\"]!=\\\"ok\\\"][[\\\"input_name\\\",\\\"status\\\"]]\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"input_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Candidatus Syntrophoarchaeum butanivorans\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"status\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"no_match\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**HTML** **generator**"
      ],
      "metadata": {
        "id": "9xSEj2JLTlq9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Rebuild HTML table with filter + download links + subgroup bullets ---\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "\n",
        "assert 'OUTPUT_DIR' in globals(), \"Run your course folder setup cell first.\"\n",
        "OUT = Path(OUTPUT_DIR)\n",
        "\n",
        "csv_path    = OUT / \"taxon_map.csv\"\n",
        "ids_path    = OUT / \"taxids_list.txt\"\n",
        "entrez_path = OUT / \"entrez_query.txt\"\n",
        "html_path   = OUT / \"taxon_map.html\"\n",
        "\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "# Normalize for display\n",
        "if \"scientific_name\" not in df.columns and \"canonical_name\" in df.columns:\n",
        "    df = df.rename(columns={\"canonical_name\":\"scientific_name\"})\n",
        "if \"superkingdom\" not in df.columns:\n",
        "    df[\"superkingdom\"] = \"\"\n",
        "\n",
        "# Counts\n",
        "total = len(df)\n",
        "counts_super = df[\"superkingdom\"].value_counts().to_dict()\n",
        "counts_egrp  = (df[df[\"superkingdom\"]==\"Eukaryota\"][\"euk_group\"]\n",
        "                .fillna(\"\").replace(\"\", \"Other/NA\").value_counts().to_dict())\n",
        "\n",
        "taxid_list   = ids_path.read_text() if ids_path.exists() else \"\"\n",
        "entrez_query = entrez_path.read_text() if entrez_path.exists() else \"\"\n",
        "\n",
        "# Pretty table\n",
        "disp_cols = [\"taxid\",\"scientific_name\",\"common_name\",\"superkingdom\",\"euk_group\",\"rank\",\"match_type\",\"status\",\"input_name\"]\n",
        "table_html = df[disp_cols].to_html(index=False, escape=True, classes=\"tax-table\")\n",
        "\n",
        "# Bullet summaries (static text you asked for)\n",
        "bullets_html = \"\"\"\n",
        "<h3 style=\"margin:14px 0 6px;\">Coverage overview</h3>\n",
        "<ul>\n",
        "  <li><strong>Bacteria (~40 taxa):</strong> <em>Escherichia coli, Bacillus subtilis, Pseudomonas aeruginosa, Staphylococcus aureus, Streptomyces coelicolor, Mycobacterium tuberculosis, Deinococcus radiodurans, Synechocystis sp. PCC 6803, Vibrio cholerae, Thermus aquaticus</em>, plus many more spread across major bacterial phyla.</li>\n",
        "  <li><strong>Archaea (~20 taxa):</strong> <em>Methanocaldococcus jannaschii, Haloferax volcanii, Halobacterium salinarum, Sulfolobus solfataricus, Thermoplasma acidophilum, Archaeoglobus fulgidus, Nitrosopumilus maritimus, Methanobrevibacter smithii</em>, etc.</li>\n",
        "  <li><strong>Eukaryotes (~40 taxa):</strong>\n",
        "      <ul>\n",
        "        <li><em>Mammals:</em> Homo sapiens, Mus musculus, Rattus norvegicus, Bos taurus, Pan troglodytes, Gorilla gorilla, Pongo abelii, Tursiops truncatus.</li>\n",
        "        <li><em>Birds/Reptiles/Fish:</em> Gallus gallus, (e.g., Anolis carolinensis), Danio rerio.</li>\n",
        "        <li><em>Plants:</em> Arabidopsis thaliana, Oryza sativa, Zea mays, Physcomitrella patens.</li>\n",
        "        <li><em>Fungi:</em> Saccharomyces cerevisiae, Neurospora crassa, Schizosaccharomyces pombe.</li>\n",
        "        <li><em>Protists:</em> Plasmodium falciparum, Trypanosoma brucei, Tetrahymena thermophila, Dictyostelium discoideum.</li>\n",
        "      </ul>\n",
        "  </li>\n",
        "</ul>\n",
        "\"\"\"\n",
        "\n",
        "html = f\"\"\"<!DOCTYPE html>\n",
        "<html lang=\"en\">\n",
        "<head>\n",
        "<meta charset=\"utf-8\">\n",
        "<title>Representative Taxa Panel (NCBI TaxIDs)</title>\n",
        "<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n",
        "<style>\n",
        "  :root {{ --bg:#0b1020; --card:#121a2b; --ink:#e5ecff; --muted:#9bb0d6; --accent:#7aa2ff; --border:#20304f; }}\n",
        "  body {{ font-family: -apple-system, BlinkMacSystemFont, \"Segoe UI\", Roboto, Inter, Arial, sans-serif; margin:0; padding:24px; background:var(--bg); color:var(--ink); }}\n",
        "  .wrap {{ max-width:1100px; margin:0 auto; background:var(--card); border:1px solid var(--border);\n",
        "          border-radius:14px; padding:22px 22px 28px; box-shadow:0 10px 30px rgba(0,0,0,.35), inset 0 1px 0 rgba(255,255,255,.04); }}\n",
        "  .muted {{ color:var(--muted); font-size:13px; }}\n",
        "  .counts span {{ background:rgba(122,162,255,.12); border:1px solid var(--border); padding:6px 10px; border-radius:10px; margin-right:8px; }}\n",
        "  .panel pre {{ background:#0a1327; border:1px solid var(--border); padding:10px 12px; border-radius:10px; overflow:auto; }}\n",
        "  .panel code {{ color:var(--accent); }}\n",
        "  .tax-table {{ width:100%; border-collapse:collapse; font-size:14px; margin-top:10px; }}\n",
        "  .tax-table th, .tax-table td {{ border:1px solid var(--border); padding:8px 10px; }}\n",
        "  .tax-table th {{ position:sticky; top:0; background:#101a32; z-index:2; }}\n",
        "  .tax-table tr:nth-child(odd) td {{ background:#0e1730; }}\n",
        "  .tax-table tr:nth-child(even) td {{ background:#0c162c; }}\n",
        "  .pill {{ display:inline-block; padding:2px 8px; border-radius:999px; border:1px solid var(--border); font-size:12px; color:var(--muted);}}\n",
        "  .filter input {{ width:100%; padding:10px 12px; border-radius:10px; border:1px solid var(--border); background:#0a1327; color:var(--ink); }}\n",
        "  ul {{ margin: 6px 0 8px 18px; }}\n",
        "</style>\n",
        "</head>\n",
        "<body>\n",
        "  <div class=\"wrap\">\n",
        "    <h1>Representative Taxa Panel <span class=\"pill\">NCBI TaxIDs</span></h1>\n",
        "    <div class=\"muted\">Built directly from your names file; shows superkingdom and eukaryote branch for teaching context.</div>\n",
        "\n",
        "    <div class=\"counts\" style=\"margin:10px 0;\">\n",
        "      <span>Total: <strong>{total}</strong></span>\n",
        "      <span>Bacteria: <strong>{counts_super.get('Bacteria', 0)}</strong></span>\n",
        "      <span>Archaea: <strong>{counts_super.get('Archaea', 0)}</strong></span>\n",
        "      <span>Eukaryota: <strong>{counts_super.get('Eukaryota', 0)}</strong></span>\n",
        "      <span>Euk¬∑Mammal: <strong>{counts_egrp.get('Mammal', 0)}</strong></span>\n",
        "      <span>Euk¬∑Bird/Reptile/Fish: <strong>{counts_egrp.get('Bird/Reptile/Fish', 0)}</strong></span>\n",
        "      <span>Euk¬∑Plant: <strong>{counts_egrp.get('Plant', 0)}</strong></span>\n",
        "      <span>Euk¬∑Fungi: <strong>{counts_egrp.get('Fungi', 0)}</strong></span>\n",
        "      <span>Euk¬∑Protist: <strong>{counts_egrp.get('Protist', 0)}</strong></span>\n",
        "    </div>\n",
        "\n",
        "    <div class=\"panel\">\n",
        "      <div><strong>Downloads:</strong>\n",
        "        <a href=\"taxon_map.csv\" download>taxon_map.csv</a> ¬∑\n",
        "        <a href=\"taxids_list.txt\" download>taxids_list.txt</a> ¬∑\n",
        "        <a href=\"entrez_query.txt\" download>entrez_query.txt</a>\n",
        "      </div>\n",
        "\n",
        "      <div class=\"filter\" style=\"margin:12px 0 6px;\">\n",
        "        <input id=\"flt\" type=\"search\" placeholder=\"Type to filter (matches any column)‚Ä¶\" oninput=\"filterRows()\">\n",
        "      </div>\n",
        "\n",
        "      <div>\n",
        "        <strong>Entrez BLAST filter:</strong>\n",
        "        <pre><code>{entrez_query}</code></pre>\n",
        "      </div>\n",
        "\n",
        "      {bullets_html}\n",
        "    </div>\n",
        "\n",
        "    {table_html}\n",
        "  </div>\n",
        "\n",
        "<script>\n",
        "function filterRows(){{\n",
        "  const q = document.getElementById('flt').value.toLowerCase();\n",
        "  const rows = document.querySelectorAll('table.tax-table tbody tr');\n",
        "  rows.forEach(tr => {{\n",
        "    tr.style.display = tr.innerText.toLowerCase().includes(q) ? '' : 'none';\n",
        "  }});\n",
        "}}\n",
        "</script>\n",
        "</body>\n",
        "</html>\n",
        "\"\"\"\n",
        "\n",
        "html_path.write_text(html, encoding=\"utf-8\")\n",
        "print(\"üåê HTML:\", html_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rn5arD3kTt25",
        "outputId": "55ce1f4e-0c86-457f-e1fa-c90ce99b7341"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üåê HTML: /content/drive/MyDrive/Teaching/BIOINFO4-5203-F25/Outputs/Taxonomy_Template/taxon_map.html\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Resolve taxon names -> NCBI TaxIDs and build BLAST Entrez query filters\n",
        "# pip install biopython\n",
        "from Bio import Entrez\n",
        "import csv, re, time\n",
        "from pathlib import Path\n",
        "\n",
        "Entrez.email = \"you@university.edu\"   # <-- set this!\n",
        "\n",
        "names_block = \"\"\"\n",
        "Oceanithermus\n",
        "Oceanithermus profundus\n",
        "Deinococcota bacterium DY0809b\n",
        "Allomeiothermus silvanus\n",
        "Meiothermus sp.\n",
        "Deinococcus sp.\n",
        "Meiothermus ruber\n",
        "Meiothermus taiwanensis\n",
        "Calidithermus roseus\n",
        "Calidithermus terrae\n",
        "Marinithermus hydrothermalis DSM 14884\n",
        "Marinithermus hydrothermalis\n",
        "Thermus thalpophilus\n",
        "Thermus brockianus\n",
        "Thermus arciformis\n",
        "Thermus tenuipuniceus\n",
        "Thermus altitudinis\n",
        "Thermus albus\n",
        "Thermus islandicus\n",
        "Thermus aquaticus\n",
        "Thermus sediminis\n",
        "Pleurocapsa sp. SU_196_0\n",
        "Deinococcus geothermalis\n",
        "Deinococcus planocerae\n",
        "Thermus scotoductus\n",
        "Hymenolepis microstoma\n",
        "Rodentolepis nana\n",
        "Mesocestoides corti\n",
        "Taenia asiatica\n",
        "Taenia crassiceps\n",
        "Echinococcus granulosus\n",
        "Echinococcus multilocularis\n",
        "Taenia solium\n",
        "Hydatigera taeniaeformis\n",
        "Phormidium sp. CCY1219\n",
        "Nostoc ellipsosporum NOK\n",
        "Vollenhovia emeryi\n",
        "Drosophila ananassae\n",
        "Nostocales cyanobacterium ELA608\n",
        "Oppiella nova]\n",
        "Rhizophagus clarus\n",
        "Lytechinus pictus\n",
        "Diadema antillarum\n",
        "Ornithodoros turicata\n",
        "Dermacentor silvarum\n",
        "Schistocerca gregaria\n",
        "Schistocerca cancellata\n",
        "Mus musculus\n",
        "Loxodonta africana\n",
        "Rousettus aegyptiacus\n",
        "Myotis myotis\n",
        "Ovis aries\n",
        "Sus scrofa\n",
        "Eschrichtius robustus\n",
        "Eschrichtius robustus\n",
        "Acropora muricata\n",
        "Acropora millepora\n",
        "Octopus vulgaris\n",
        "Oscillatoriaceae cyanobacterium\n",
        "Halobacteriales archaeon\n",
        "Cyanobacteriota bacterium\n",
        "Leptolyngbya sp. 7M\n",
        "Thermoplasmata archaeon\n",
        "Nitrosotalea sp.\n",
        "Candidatus Micrarchaeia archaeon\n",
        "Synechococcus sp. RC10A2\n",
        "Kamptonema cortianum\n",
        "Nitrososphaerota archaeon\n",
        "Candidatus Woesearchaeota archaeon\n",
        "Thermosynechococcus sp.\n",
        "Thermosynechococcaceae cyanobacterium\n",
        "Hydrococcus sp. Prado102\n",
        "Scytonema sp. NUACC21\n",
        "Cyanobacteria bacterium P01_D01_bin.50\n",
        "Mojavia pulchra JT2-VF2\n",
        "Aulosira sp. DedQUE10\n",
        "Tolypothrix tenuis\n",
        "Desmonostoc muscorum\n",
        "Komarekiella delphini-convector\n",
        "Leptolyngbya sp. NIES-2104\n",
        "Leptolyngbya sp. NIES-3755\n",
        "Hyella patelloides\n",
        "Planktothrix sp.\n",
        "Oculatellaceae cyanobacterium bins.114\n",
        "Waterburya sp.\n",
        "Allocoleopsis franciscana\n",
        "Coleofasciculaceae cyanobacterium\n",
        "Candidatus Cyanaurora vandensis\n",
        "Anthocerotibacter panamensis\n",
        "Gloeobacter kilaueensis\n",
        "Gloeobacterales cyanobacterium ES-bin-313\n",
        "Methanolobus sp.\n",
        "Methanosarcinaceae archaeon\n",
        "Methanosalsum zhilinae\n",
        "Methanobacteriota archaeon\n",
        "Methanobacteriota archaeon\n",
        "Candidatus Sysuiplasma superficiale\n",
        "Methanomassiliicoccales archaeon\n",
        "Thermoplasmatales archaeon I-plasma\n",
        "Ferroplasma sp.\n",
        "Thermoplasma sp.\n",
        "Thermoplasma volcanium GSS1\n",
        "Thermoplasma volcanium\n",
        "Oxyplasma meridianum\n",
        "Thermoplasmatales archaeon Gpl\n",
        "Cuniculiplasma divulgatum\n",
        "archaeon BMS3Bbin15\n",
        "Methanobacteriota archaeon\n",
        "Candidatus Hydrothermarchaeaceae archaeon\n",
        "uncultured archaeon\n",
        "Candidatus Argoarchaeum ethanivorans\n",
        "Candidatus Methanoperedens sp.\n",
        "Candidatus Syntrophoarchaeum butanivorans\n",
        "Candidatus Syntrophoarchaeum sp. WYZ-LMO15\n",
        "\"\"\".strip().splitlines()\n",
        "\n",
        "# ---------- cleaning helpers ----------\n",
        "bad_tokens = [\n",
        "    r\"\\bDSM\\s*\\d+\\b\", r\"\\bNOK\\b\", r\"\\bGSS1\\b\", r\"\\bbin\\.?\\s*\\d+\\b\",\n",
        "    r\"\\bbins?\\.?\\s*\\d+\\b\", r\"\\bELA\\d+\\w*\\b\", r\"\\bSU_\\d+_\\d+\\b\", r\"\\bPrado\\d+\\b\",\n",
        "    r\"\\bP\\d+_\\w+\\b\", r\"\\bJT\\d+-\\w+\\b\", r\"\\bWYZ-\\w+\\b\", r\"\\bES-bin-\\d+\\b\", r\"]$\"\n",
        "]\n",
        "generic_words = (\"bacterium\", \"archaeon\", \"cyanobacterium\", \"cyanobacteria\", \"family\", \"order\")\n",
        "\n",
        "def clean_name(s: str) -> str:\n",
        "    s = s.strip()\n",
        "    for pat in bad_tokens:\n",
        "        s = re.sub(pat, \"\", s, flags=re.I)\n",
        "    s = re.sub(r\"\\s+\", \" \", s).strip(\" .\")\n",
        "    return s\n",
        "\n",
        "def genus_of_sp(name: str) -> str | None:\n",
        "    m = re.search(r\"^([A-Z][a-zA-Z_-]+)\\s+sp\\.\", name)\n",
        "    return m.group(1) if m else None\n",
        "\n",
        "def primary_trim(name: str) -> str:\n",
        "    # collapse \"X cyanobacterium ...\" -> \"X cyanobacterium\"\n",
        "    m = re.search(r\"^(.*?\\b(?:%s))\\b\" % \"|\".join(generic_words), name, flags=re.I)\n",
        "    return m.group(1) if m else name\n",
        "\n",
        "def need_expansion(original: str, rank: str) -> bool:\n",
        "    # Recommend :exp for sp./generic/above-species ranks\n",
        "    return (\n",
        "        \" sp.\" in original\n",
        "        or any(w in original.lower() for w in generic_words)\n",
        "        or rank not in (\"species\", \"subspecies\", \"no rank\")  # genus/family/etc.\n",
        "    )\n",
        "\n",
        "# ---------- NCBI lookup ----------\n",
        "def tax_lookup(name: str):\n",
        "    \"\"\"Return dict with taxid, canonical, rank, note.\"\"\"\n",
        "    queries = [\n",
        "        f\"\\\"{name}\\\"[SCIN]\",    # exact scientific name\n",
        "        name,                   # general search\n",
        "    ]\n",
        "    # If 'sp.' present, add genus fallback\n",
        "    g = genus_of_sp(name)\n",
        "    if g:\n",
        "        queries.append(f\"\\\"{g}\\\"[SCIN]\")\n",
        "        queries.append(g)\n",
        "\n",
        "    # If generic like 'family/order bacterium/archaeon', trim trailing strain codes\n",
        "    trimmed = primary_trim(name)\n",
        "    if trimmed != name:\n",
        "        queries.insert(1, f\"\\\"{trimmed}\\\"[SCIN]\")\n",
        "        queries.insert(2, trimmed)\n",
        "\n",
        "    seen = set()\n",
        "    for q in queries:\n",
        "        if q in seen:\n",
        "            continue\n",
        "        seen.add(q)\n",
        "        h = Entrez.esearch(db=\"taxonomy\", term=q, retmode=\"xml\")\n",
        "        r = Entrez.read(h); h.close()\n",
        "        if int(r[\"Count\"]) == 0:\n",
        "            continue\n",
        "        tid = r[\"IdList\"][0]\n",
        "        h2 = Entrez.efetch(db=\"taxonomy\", id=tid, retmode=\"xml\")\n",
        "        rec = Entrez.read(h2); h2.close()\n",
        "        node = rec[0]\n",
        "        return {\n",
        "            \"taxid\": int(tid),\n",
        "            \"canonical\": node.get(\"ScientificName\", \"\"),\n",
        "            \"rank\": node.get(\"Rank\", \"\"),\n",
        "            \"note\": f\"matched via {q}\"\n",
        "        }\n",
        "        # (Optionally: inspect node['LineageEx'] for more logic)\n",
        "    return {\"taxid\": \"\", \"canonical\": \"\", \"rank\": \"\", \"note\": \"no match\"}\n",
        "\n",
        "# ---------- main ----------\n",
        "rows = []\n",
        "seen_inputs = set()\n",
        "for raw in names_block:\n",
        "    if not raw.strip():\n",
        "        continue\n",
        "    original = raw.strip()\n",
        "    if original in seen_inputs:\n",
        "        continue\n",
        "    seen_inputs.add(original)\n",
        "\n",
        "    cleaned = clean_name(original)\n",
        "    info = tax_lookup(cleaned)\n",
        "    sugg = \"Organism:exp\" if need_expansion(original, info.get(\"rank\",\"\")) else \"Organism:noexp\"\n",
        "\n",
        "    rows.append({\n",
        "        \"input_name\": original,\n",
        "        \"cleaned_name\": cleaned,\n",
        "        \"taxid\": info[\"taxid\"],\n",
        "        \"canonical_name\": info[\"canonical\"],\n",
        "        \"rank\": info[\"rank\"],\n",
        "        \"suggested_field\": sugg,\n",
        "        \"note\": info[\"note\"]\n",
        "    })\n",
        "    time.sleep(0.34)  # be courteous to NCBI\n",
        "\n",
        "# Write CSVs\n",
        "with open(\"taxon_map.csv\",\"w\",newline=\"\") as f:\n",
        "    w = csv.DictWriter(f, fieldnames=[\n",
        "        \"input_name\",\"cleaned_name\",\"taxid\",\"canonical_name\",\"rank\",\"suggested_field\",\"note\"\n",
        "    ])\n",
        "    w.writeheader(); w.writerows(rows)\n",
        "\n",
        "# Unresolved\n",
        "unresolved = [r for r in rows if not r[\"taxid\"]]\n",
        "if unresolved:\n",
        "    with open(\"unresolved.csv\",\"w\",newline=\"\") as f:\n",
        "        w = csv.DictWriter(f, fieldnames=[\n",
        "            \"input_name\",\"cleaned_name\",\"note\"\n",
        "        ])\n",
        "        w.writeheader();\n",
        "        for r in unresolved:\n",
        "            w.writerow({k:r[k] for k in (\"input_name\",\"cleaned_name\",\"note\")})\n",
        "\n",
        "# Unique TaxIDs\n",
        "taxids = sorted({str(r[\"taxid\"]) for r in rows if r[\"taxid\"]})\n",
        "Path(\"taxids.txt\").write_text(\"\\n\".join(taxids))\n",
        "\n",
        "# Build two Entrez query strings (limit length as needed for URLs)\n",
        "tokens_noexp = [f\"txid{t}[Organism:noexp]\" for t in taxids]\n",
        "tokens_exp   = []\n",
        "for r in rows:\n",
        "    if r[\"taxid\"]:\n",
        "        field = \"Organism:exp\" if r[\"suggested_field\"]==\"Organism:exp\" else \"Organism:noexp\"\n",
        "        tokens_exp.append(f\"txid{r['taxid']}[{field}]\")\n",
        "\n",
        "# Deduplicate while preserving order\n",
        "def dedup(seq):\n",
        "    s, out = set(), []\n",
        "    for x in seq:\n",
        "        if x not in s:\n",
        "            s.add(x); out.append(x)\n",
        "    return out\n",
        "\n",
        "eq_noexp = \" OR \".join(dedup(tokens_noexp))\n",
        "eq_exp   = \" OR \".join(dedup(tokens_exp))\n",
        "\n",
        "Path(\"entrez_query_noexp.txt\").write_text(eq_noexp)\n",
        "Path(\"entrez_query_exp.txt\").write_text(eq_exp)\n",
        "\n",
        "print(f\"Resolved {len(taxids)} unique TaxIDs out of {len(rows)} names.\")\n",
        "print(\"Wrote: taxon_map.csv, taxids.txt, entrez_query_noexp.txt, entrez_query_exp.txt\")\n",
        "if unresolved:\n",
        "    print(f\"{len(unresolved)} unresolved -> unresolved.csv\")"
      ],
      "metadata": {
        "id": "KBP3pSuufN8e",
        "outputId": "b0132823-213f-4279-abb2-42ed4e34e8af",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resolved 107 unique TaxIDs out of 111 names.\n",
            "Wrote: taxon_map.csv, taxids.txt, entrez_query_noexp.txt, entrez_query_exp.txt\n",
            "2 unresolved -> unresolved.csv\n"
          ]
        }
      ]
    }
  ]
}