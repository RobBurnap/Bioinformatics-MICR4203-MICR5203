{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM4t3ZuNiy5kiFm/a0RqfCr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RobBurnap/Bioinformatics-MICR4203-MICR5203/blob/main/notebooks/taxonomic_codes_ipynb_v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Developing a taxonomic table for taxonomic codes for a diverse set of sequences**"
      ],
      "metadata": {
        "id": "afZn240E8-8I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "BIOINFO4/5203 — Colab Exercise Template\n",
        "\n",
        "Use this template for every weekly exercise. It standardizes setup, data paths, and the final summary so grading in Canvas is quick.\n",
        "\n",
        "Workflow\n",
        "\n",
        "    Click the \"Open in Colab\" link in Canvas (points to this notebook in GitHub).\n",
        "    Run Setup cells (installs and mounts Google Drive).\n",
        "    Run the Exercise cells (edit as instructed for each lecture).\n",
        "    Verify the Results Summary prints the values requested by Canvas.\n",
        "    File → Print → Save as PDF and upload .ipynb + PDF to Canvas.\n",
        "\n",
        "    Instructor note (delete in student copy if desired):\n",
        "\n",
        "        Place datasets for this lecture at: Drive → BIOINFO4-5203-F25 → Data → Lxx_topic\n",
        "        Update the constants in Config below: COURSE_DIR, LECTURE_CODE (e.g., L05), and TOPIC.\n",
        "        For heavy jobs (trees, assemblies), provide the PETE output files in the same Data folder so students can analyze them here if the queue is busy.\n",
        "\n"
      ],
      "metadata": {
        "id": "frmCc0lAQcYQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Auto‑setup + course folder (uses your Teaching path)**"
      ],
      "metadata": {
        "id": "bw0BsPOEGVL3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##A. Mount Google Drive, Import Coding Libraries Necessary for Running Subsequent Code"
      ],
      "metadata": {
        "id": "6JW7liKMC3H-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Install FIRST, then import\n",
        "%pip install -q biopython       # Install the Biopython package quietly (-q suppresses most output) so we can work with biological sequence files\n",
        "\n",
        "from google.colab import drive  # Import the module that lets Colab interact with Google Drive\n",
        "drive.mount('/content/drive')   # Mount your Google Drive so it appears in Colab's file system under /content/drive\n",
        "\n",
        "import os, pandas as pd          # Import 'os' for file/directory operations, and pandas for working with data tables\n",
        "from Bio import SeqIO            # Import SeqIO from Biopython for reading/writing biological sequence files (FASTA, GenBank, etc.)\n",
        "import matplotlib.pyplot as plt  # Import Matplotlib's plotting library to create figures and graphs\n",
        "\n",
        "print(\"✅ Dependencies installed & Drive mounted.\")\n"
      ],
      "metadata": {
        "id": "N1NrV2YaGfZ_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ee8bf4b-d28c-44bb-dbe1-c9876c13206a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/3.3 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/3.3 MB\u001b[0m \u001b[31m56.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m46.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hMounted at /content/drive\n",
            "✅ Dependencies installed & Drive mounted.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## B. Course folders: Define the course folders for places to load data to be processed and output to be saved\n",
        "\n",
        "Edit only `LECTURE_CODE` and `TOPIC` if needed. All inputs will live in `Data/LECTURE_TOPIC` and outputs in `Outputs/LECTURE_TOPIC`."
      ],
      "metadata": {
        "id": "j7uJVzrKC-8v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2) Define file sturcture"
      ],
      "metadata": {
        "id": "onPHWY4dGku-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# --- Course folder config (customize LECTURE_CODE/TOPIC only) ---\n",
        "COURSE_DIR   = \"/content/drive/MyDrive/Teaching/BIOINFO4-5203-F25\"\n",
        "LECTURE_CODE = \"Taxonomy\"            # change per week (e.g., L02, L03, ...)\n",
        "TOPIC        = \"Template\"    # short slug for the exercise\n",
        "\n",
        "# Derived paths (do not change)\n",
        "DATA_DIR   = f\"{COURSE_DIR}/Data/{LECTURE_CODE}_{TOPIC}\"\n",
        "OUTPUT_DIR = f\"{COURSE_DIR}/Outputs/{LECTURE_CODE}_{TOPIC}\"\n",
        "\n",
        "# Create folder structure if missing\n",
        "for p in [f\"{COURSE_DIR}/Data\", f\"{COURSE_DIR}/Outputs\", f\"{COURSE_DIR}/Notebooks\", DATA_DIR, OUTPUT_DIR]:\n",
        "    os.makedirs(p, exist_ok=True)\n",
        "\n",
        "print(\"📁 COURSE_DIR :\", COURSE_DIR)\n",
        "print(\"📁 DATA_DIR   :\", DATA_DIR)\n",
        "print(\"📁 OUTPUT_DIR :\", OUTPUT_DIR)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C1wyBalSGox_",
        "outputId": "48d4e7c2-d66a-49d4-9d90-88d31b4dc957"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📁 COURSE_DIR : /content/drive/MyDrive/Teaching/BIOINFO4-5203-F25\n",
            "📁 DATA_DIR   : /content/drive/MyDrive/Teaching/BIOINFO4-5203-F25/Data/Taxonomy_Template\n",
            "📁 OUTPUT_DIR : /content/drive/MyDrive/Teaching/BIOINFO4-5203-F25/Outputs/Taxonomy_Template\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Take file name \"taxonomic_cmmon_names\" and find taxonomic ids"
      ],
      "metadata": {
        "id": "H1Qe2LFAFz5A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3) Version 3 Aug 25"
      ],
      "metadata": {
        "id": "ccijET3tGsBf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Build panel from your full names file & write CSV + TXT outputs ---\n",
        "from Bio import Entrez\n",
        "from pathlib import Path\n",
        "import pandas as pd, io, re, os, sys, time\n",
        "\n",
        "# REQUIRED: set your email; optionally set your NCBI API key for higher rate limits\n",
        "Entrez.email = \"you@university.edu\"\n",
        "# Entrez.api_key = \"YOUR_NCBI_API_KEY\"  # optional\n",
        "\n",
        "# Expect these from your course scaffold cell\n",
        "assert 'DATA_DIR' in globals() and 'OUTPUT_DIR' in globals(), \"Run your course folder setup cell first.\"\n",
        "DATA_DIR = Path(DATA_DIR); OUT = Path(OUTPUT_DIR)\n",
        "OUT.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Locate your master names file (exact name you’ve been using)\n",
        "CANDIDATES = [\n",
        "    DATA_DIR / \"taxonomic_common_names\",\n",
        "    DATA_DIR / \"taxonomic_common_names.txt\",\n",
        "    DATA_DIR / \"taxonomic_common_names.csv\",\n",
        "    DATA_DIR / \"taxonomic_common_names.tsv\",\n",
        "]\n",
        "NAMES_PATH = next((p for p in CANDIDATES if p.exists()), None)\n",
        "if not NAMES_PATH:\n",
        "    raise FileNotFoundError(\n",
        "        f\"Could not find 'taxonomic_cmmon_names' (txt/csv/tsv) in {DATA_DIR}.\\n\"\n",
        "        \"Create it with one name per line (scientific or common).\"\n",
        "    )\n",
        "print(\"📄 Names file:\", NAMES_PATH)\n",
        "\n",
        "def load_names(path: Path):\n",
        "    text = path.read_text(errors=\"ignore\")\n",
        "    head = \"\\n\".join(text.splitlines()[:5])\n",
        "    is_table = (\",\" in head) or (\"\\t\" in head)\n",
        "    names = []\n",
        "    if is_table:\n",
        "        sep = \"\\t\" if \"\\t\" in head else \",\"\n",
        "        df = pd.read_csv(io.StringIO(text), sep=sep, comment=\"#\", header=None)\n",
        "        col0 = df.columns[0]\n",
        "        names = [str(x).strip() for x in df[col0].tolist() if str(x).strip()]\n",
        "    else:\n",
        "        for line in text.splitlines():\n",
        "            line = line.strip()\n",
        "            if line and not line.startswith(\"#\"):\n",
        "                names.append(line)\n",
        "    return names\n",
        "\n",
        "raw_names = load_names(NAMES_PATH)\n",
        "print(f\"📝 Loaded {len(raw_names)} name(s)\")\n",
        "\n",
        "def fetch_taxnode_by_id(tid: str):\n",
        "    h2 = Entrez.efetch(db=\"taxonomy\", id=tid, retmode=\"xml\")\n",
        "    rec = Entrez.read(h2); h2.close()\n",
        "    return rec[0] if rec else {}\n",
        "\n",
        "def tax_lookup(name: str):\n",
        "    \"\"\"\n",
        "    Try to resolve a line like 'Homo sapiens' or 'Human' → (taxid, canonical, rank, domain, match_type, status)\n",
        "    - match_type: SCIN | COMMON | LOOSE | TAXID\n",
        "    - domain from LineageEx: Bacteria / Archaea / Eukaryota (default 'NA' if unknown)\n",
        "    \"\"\"\n",
        "    name = name.strip()\n",
        "    # If it's already an integer TaxID, accept directly\n",
        "    if re.fullmatch(r\"\\d+\", name):\n",
        "        try:\n",
        "            node = fetch_taxnode_by_id(name)\n",
        "            dom = next((x[\"ScientificName\"] for x in node.get(\"LineageEx\", [])\n",
        "                        if x.get(\"Rank\") == \"superkingdom\"), \"NA\")\n",
        "            return int(name), node.get(\"ScientificName\",\"\"), node.get(\"Rank\",\"\"), dom, \"TAXID\", \"ok\"\n",
        "        except Exception as e:\n",
        "            return \"\", \"\", \"\", \"NA\", \"TAXID\", f\"efetch_failed:{e}\"\n",
        "\n",
        "    queries = [\n",
        "        (f\"\\\"{name}\\\"[SCIN]\",   \"SCIN\"),\n",
        "        (f\"\\\"{name}\\\"[Common Name]\", \"COMMON\"),\n",
        "        (name,                 \"LOOSE\"),\n",
        "    ]\n",
        "    for q, tag in queries:\n",
        "        try:\n",
        "            h = Entrez.esearch(db=\"taxonomy\", term=q, retmode=\"xml\"); r = Entrez.read(h); h.close()\n",
        "            if int(r[\"Count\"]) == 0:\n",
        "                continue\n",
        "            tid = r[\"IdList\"][0]\n",
        "            node = fetch_taxnode_by_id(tid)\n",
        "            dom = next((x[\"ScientificName\"] for x in node.get(\"LineageEx\", [])\n",
        "                        if x.get(\"Rank\") == \"superkingdom\"), \"NA\")\n",
        "            return int(tid), node.get(\"ScientificName\",\"\"), node.get(\"Rank\",\"\"), dom, tag, \"ok\"\n",
        "        except Exception as e:\n",
        "            sys.stderr.write(f\"[warn] lookup '{name}' via {tag}: {e}\\n\")\n",
        "            time.sleep(0.15)\n",
        "            continue\n",
        "    return \"\", \"\", \"\", \"NA\", \"NA\", \"no_match\"\n",
        "\n",
        "rows = []\n",
        "seen = set()\n",
        "for nm in raw_names:\n",
        "    key = nm.strip().lower()\n",
        "    if not key or key in seen:\n",
        "        continue\n",
        "    seen.add(key)\n",
        "    tid, canon, rank, dom, tag, status = tax_lookup(nm)\n",
        "    rows.append({\n",
        "        \"input_name\": nm,\n",
        "        \"taxid\": tid,\n",
        "        \"canonical_name\": canon,\n",
        "        \"rank\": rank,\n",
        "        \"domain\": dom,\n",
        "        \"match_type\": tag,\n",
        "        \"status\": status\n",
        "    })\n",
        "    time.sleep(0.25)  # be polite to NCBI; increase if you hit rate limits\n",
        "\n",
        "df = pd.DataFrame(rows)\n",
        "df = df.sort_values([\"status\",\"domain\",\"canonical_name\",\"input_name\"], na_position=\"last\").reset_index(drop=True)\n",
        "\n",
        "# Write outputs\n",
        "map_csv = OUT / \"taxon_map.csv\"\n",
        "ids_txt = OUT / \"taxids_list.txt\"\n",
        "entrez_txt = OUT / \"entrez_query.txt\"\n",
        "\n",
        "df.to_csv(map_csv, index=False)\n",
        "valid_taxids = [str(t) for t in df[\"taxid\"].tolist() if str(t).isdigit()]\n",
        "ids_txt.write_text(\"\\n\".join(valid_taxids))\n",
        "entrez_txt.write_text(\" OR \".join([f\"txid{t}[ORGN]\" for t in valid_taxids]))\n",
        "\n",
        "print(\"🗺  Map CSV :\", map_csv)\n",
        "print(\"🧬 TaxIDs  :\", ids_txt)\n",
        "print(\"🔎 ENTREQ  :\", entrez_txt)\n",
        "\n",
        "# Report summary\n",
        "print(\"\\n=== Summary ===\")\n",
        "print(\"Total names read :\", len(raw_names))\n",
        "print(\"Resolved (ok)    :\", (df[\"status\"]==\"ok\").sum())\n",
        "print(\"Unresolved       :\", (df[\"status\"]!=\"ok\").sum())\n",
        "if (df[\"status\"]!=\"ok\").any():\n",
        "    print(df[df[\"status\"]!=\"ok\"][[\"input_name\",\"status\"]].head(12))"
      ],
      "metadata": {
        "id": "H2dejbPgSSSg",
        "outputId": "8536b9b4-d60d-45fa-b862-19346028bd0b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📄 Names file: /content/drive/MyDrive/Teaching/BIOINFO4-5203-F25/Data/Taxonomy_Template/taxonomic_common_names.txt\n",
            "📝 Loaded 127 name(s)\n",
            "🗺  Map CSV : /content/drive/MyDrive/Teaching/BIOINFO4-5203-F25/Outputs/Taxonomy_Template/taxon_map.csv\n",
            "🧬 TaxIDs  : /content/drive/MyDrive/Teaching/BIOINFO4-5203-F25/Outputs/Taxonomy_Template/taxids_list.txt\n",
            "🔎 ENTREQ  : /content/drive/MyDrive/Teaching/BIOINFO4-5203-F25/Outputs/Taxonomy_Template/entrez_query.txt\n",
            "\n",
            "=== Summary ===\n",
            "Total names read : 127\n",
            "Resolved (ok)    : 123\n",
            "Unresolved       : 1\n",
            "                                  input_name    status\n",
            "0  Candidatus Syntrophoarchaeum butanivorans  no_match\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**HTML** **generator**"
      ],
      "metadata": {
        "id": "9xSEj2JLTlq9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Rebuild HTML table with filter + download links (reads from OUT) ---\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "\n",
        "assert 'OUTPUT_DIR' in globals(), \"Run your course folder setup cell first.\"\n",
        "OUT = Path(OUTPUT_DIR)\n",
        "\n",
        "csv_path   = OUT / \"taxon_map.csv\"\n",
        "ids_path   = OUT / \"taxids_list.txt\"\n",
        "entrez_path= OUT / \"entrez_query.txt\"\n",
        "html_path  = OUT / \"taxon_map.html\"\n",
        "\n",
        "df = pd.read_csv(csv_path)\n",
        "df = df.sort_values([\"domain\",\"scientific_name\",\"common_name\"] if \"common_name\" in df.columns else [\"domain\",\"canonical_name\"])\n",
        "\n",
        "taxid_list  = ids_path.read_text() if ids_path.exists() else \"\"\n",
        "entrez_query= entrez_path.read_text() if entrez_path.exists() else \"\"\n",
        "\n",
        "# For display, prefer canonical_name if present\n",
        "display_df = df.copy()\n",
        "if \"canonical_name\" in display_df.columns and \"scientific_name\" not in display_df.columns:\n",
        "    display_df = display_df.rename(columns={\"canonical_name\":\"scientific_name\"})\n",
        "\n",
        "counts = display_df[\"domain\"].value_counts().to_dict()\n",
        "total  = len(display_df)\n",
        "\n",
        "table_html = display_df.to_html(index=False, escape=True, classes=\"tax-table\")\n",
        "\n",
        "html = f\"\"\"<!DOCTYPE html>\n",
        "<html lang=\"en\">\n",
        "<head>\n",
        "<meta charset=\"utf-8\">\n",
        "<title>Representative Taxa Panel (NCBI TaxIDs)</title>\n",
        "<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n",
        "<style>\n",
        "  :root {{ --bg:#0b1020; --card:#121a2b; --ink:#e5ecff; --muted:#9bb0d6; --accent:#7aa2ff; --border:#20304f; }}\n",
        "  body {{ font-family: -apple-system, BlinkMacSystemFont, \"Segoe UI\", Roboto, Inter, Arial, sans-serif; margin:0; padding:24px; background:var(--bg); color:var(--ink); }}\n",
        "  .wrap {{ max-width:1100px; margin:0 auto; background:var(--card); border:1px solid var(--border);\n",
        "          border-radius:14px; padding:22px 22px 28px; box-shadow:0 10px 30px rgba(0,0,0,.35), inset 0 1px 0 rgba(255,255,255,.04); }}\n",
        "  .muted {{ color:var(--muted); font-size:13px; }}\n",
        "  .counts span {{ background:rgba(122,162,255,.12); border:1px solid var(--border); padding:6px 10px; border-radius:10px; margin-right:8px; }}\n",
        "  .panel pre {{ background:#0a1327; border:1px solid var(--border); padding:10px 12px; border-radius:10px; overflow:auto; }}\n",
        "  .panel code {{ color:var(--accent); }}\n",
        "  .tax-table {{ width:100%; border-collapse:collapse; font-size:14px; margin-top:10px; }}\n",
        "  .tax-table th, .tax-table td {{ border:1px solid var(--border); padding:8px 10px; }}\n",
        "  .tax-table th {{ position:sticky; top:0; background:#101a32; z-index:2; }}\n",
        "  .tax-table tr:nth-child(odd) td {{ background:#0e1730; }}\n",
        "  .tax-table tr:nth-child(even) td {{ background:#0c162c; }}\n",
        "  .pill {{ display:inline-block; padding:2px 8px; border-radius:999px; border:1px solid var(--border); font-size:12px; color:var(--muted);}}\n",
        "  .filter input {{ width:100%; padding:10px 12px; border-radius:10px; border:1px solid var(--border); background:#0a1327; color:var(--ink); }}\n",
        "</style>\n",
        "</head>\n",
        "<body>\n",
        "  <div class=\"wrap\">\n",
        "    <h1>Representative Taxa Panel <span class=\"pill\">NCBI TaxIDs</span></h1>\n",
        "    <div class=\"muted\">Built directly from your names file; counts and table reflect the full list.</div>\n",
        "    <div class=\"counts\">\n",
        "      <span>Total: <strong>{total}</strong></span>\n",
        "      <span>Bacteria: <strong>{counts.get('Bacteria', 0)}</strong></span>\n",
        "      <span>Archaea: <strong>{counts.get('Archaea', 0)}</strong></span>\n",
        "      <span>Eukaryota: <strong>{counts.get('Eukaryota', 0)}</strong></span>\n",
        "    </div>\n",
        "\n",
        "    <div class=\"panel\">\n",
        "      <div><strong>Downloads:</strong>\n",
        "        <a href=\"taxon_map.csv\" download>taxon_map.csv</a> ·\n",
        "        <a href=\"taxids_list.txt\" download>taxids_list.txt</a> ·\n",
        "        <a href=\"entrez_query.txt\" download>entrez_query.txt</a>\n",
        "      </div>\n",
        "\n",
        "      <div class=\"filter\" style=\"margin:12px 0 6px;\">\n",
        "        <input id=\"flt\" type=\"search\" placeholder=\"Type to filter (matches any column)…\" oninput=\"filterRows()\">\n",
        "      </div>\n",
        "\n",
        "      <div>\n",
        "        <strong>Entrez BLAST filter:</strong>\n",
        "        <pre><code>{entrez_query}</code></pre>\n",
        "      </div>\n",
        "    </div>\n",
        "\n",
        "    {table_html}\n",
        "  </div>\n",
        "\n",
        "<script>\n",
        "function filterRows(){{\n",
        "  const q = document.getElementById('flt').value.toLowerCase();\n",
        "  const rows = document.querySelectorAll('table.tax-table tbody tr');\n",
        "  rows.forEach(tr => {{\n",
        "    tr.style.display = tr.innerText.toLowerCase().includes(q) ? '' : 'none';\n",
        "  }});\n",
        "}}\n",
        "</script>\n",
        "</body>\n",
        "</html>\n",
        "\"\"\"\n",
        "\n",
        "html_path.write_text(html, encoding=\"utf-8\")\n",
        "print(\"🌐 HTML:\", html_path)"
      ],
      "metadata": {
        "id": "Rn5arD3kTt25",
        "outputId": "55ce1f4e-0c86-457f-e1fa-c90ce99b7341",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🌐 HTML: /content/drive/MyDrive/Teaching/BIOINFO4-5203-F25/Outputs/Taxonomy_Template/taxon_map.html\n"
          ]
        }
      ]
    }
  ]
}