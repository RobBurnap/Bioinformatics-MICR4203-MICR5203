{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RobBurnap/Bioinformatics-MICR4203-MICR5203/blob/main/notebooks/L02%E2%80%93BLASTn_Mini%E2%80%91API.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "275544ee",
      "metadata": {
        "id": "275544ee"
      },
      "source": [
        "\n",
        "# BIOINFO4/5203 — Week 2 Exercise (Foundations)\n",
        "\n",
        "**Goals for today**\n",
        "- Mount Google Drive and create your course folders\n",
        "- Load a small FASTA file\n",
        "- Compute simple sequence statistics\n",
        "- Save a plot and a summary text into your `Outputs/` folder\n",
        "\n",
        "> **Deliverables to Canvas:** the executed notebook (`.ipynb`) and a PDF export with outputs visible.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Cell 1 — Setup Google Drive + Week Folders"
      ],
      "metadata": {
        "id": "fU6YPxFnnl1Y"
      },
      "id": "fU6YPxFnnl1Y"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "269c6b87",
      "metadata": {
        "id": "269c6b87"
      },
      "outputs": [],
      "source": [
        "# --- L02 SETUP: mount Google Drive and make week folders ---\n",
        "%pip -q install biopython\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "\n",
        "# Your course root in Drive (change only if you chose a different root in L01)\n",
        "COURSE_DIR   = \"/content/drive/MyDrive/Teaching/BIOINFO4-5203-F25\"\n",
        "\n",
        "# Week label for L02 (used to create subfolders)\n",
        "LECTURE_CODE = \"L02_databases_formats\"\n",
        "TOPIC        = \"blastn_seed\"\n",
        "\n",
        "# Per-week data/output folders\n",
        "DATA_DIR    = f\"{COURSE_DIR}/Data/{LECTURE_CODE}_{TOPIC}\"\n",
        "OUTPUT_DIR  = f\"{COURSE_DIR}/Outputs/{LECTURE_CODE}_{TOPIC}\"\n",
        "for p in [COURSE_DIR, f\"{COURSE_DIR}/Data\", f\"{COURSE_DIR}/Outputs\", DATA_DIR, OUTPUT_DIR]:\n",
        "    os.makedirs(p, exist_ok=True)\n",
        "\n",
        "print(\"✅ Drive mounted.\")\n",
        "print(\"📁 COURSE_DIR :\", COURSE_DIR)\n",
        "print(\"📁 DATA_DIR   :\", DATA_DIR)\n",
        "print(\"📁 OUTPUT_DIR :\", OUTPUT_DIR)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TESTING"
      ],
      "metadata": {
        "id": "rpef2mlCCqgt"
      },
      "id": "rpef2mlCCqgt"
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Robust BLASTn cascade: refseq_rna -> refseq_genomic -> nt (mega then sensitive) ---\n",
        "from Bio import Entrez, SeqIO\n",
        "from Bio.Blast import NCBIWWW, NCBIXML\n",
        "import io, os, time\n",
        "\n",
        "Entrez.email = \"rob.burnap@okstate.edu\"  # <-- set this\n",
        "\n",
        "assert 'FASTA_PATH' in globals() and 'OUTPUT_DIR' in globals(), \"Run setup first.\"\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "rec = next(SeqIO.parse(FASTA_PATH, \"fasta\"))\n",
        "query_seq = str(rec.seq).upper().replace(\" \", \"\").replace(\"\\n\", \"\")\n",
        "print(f\"🔎 Query: {rec.id} (len={len(query_seq)} nt)\")\n",
        "if len(query_seq) < 30:\n",
        "    print(\"⚠️ Query is short (<30 nt). Consider using a longer region for BLASTn.\")\n",
        "\n",
        "def run_qblast(db, seq, megablast=True, expect=1e-5, extra_query=None):\n",
        "    print(f\"⏳ Trying BLASTn vs {db}  (megablast={megablast}, E={expect})\")\n",
        "    h = NCBIWWW.qblast(\n",
        "        program=\"blastn\",\n",
        "        database=db,\n",
        "        sequence=seq,\n",
        "        expect=expect,\n",
        "        megablast=megablast,\n",
        "        filter=\"L\",\n",
        "        entrez_query=extra_query\n",
        "    )\n",
        "    xml = h.read(); h.close()\n",
        "    rec = NCBIXML.read(io.StringIO(xml))\n",
        "    return rec, xml\n",
        "\n",
        "attempts = [\n",
        "    (\"refseq_rna\",       True,  1e-5, \"srcdb_refseq[PROP] AND biomol_mrna[PROP]\"),\n",
        "    (\"refseq_genomic\",   True,  1e-5, None),\n",
        "    (\"nt\",               True,  1e-5, None),\n",
        "    (\"nt\",               False, 1e-3, None),  # more sensitive\n",
        "]\n",
        "\n",
        "record = None\n",
        "xml_used = None\n",
        "db_used = None\n",
        "for db, mega, ecut, q in attempts:\n",
        "    try:\n",
        "        r, xml = run_qblast(db, query_seq, megablast=mega, expect=ecut, extra_query=q)\n",
        "        if r.alignments:\n",
        "            record, xml_used, db_used = r, xml, f\"{db} (megablast={mega}, E={ecut})\"\n",
        "            print(f\"✅ Hits found in: {db_used}\")\n",
        "            break\n",
        "        else:\n",
        "            print(f\"— No hits in {db} (megablast={mega})\")\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ BLAST attempt failed for {db}: {e}\")\n",
        "    time.sleep(0.5)\n",
        "\n",
        "if record is None or not record.alignments:\n",
        "    raise AssertionError(\"No BLASTn hits in refseq_rna/refseq_genomic/nt. Try a longer or different query.\")\n",
        "\n",
        "# Save XML named for the database used\n",
        "xml_basename = f\"blastn_{db_used.replace(' ', '_').replace('=', '').replace(',', '').replace('(', '').replace(')', '')}.xml\"\n",
        "xml_path = os.path.join(OUTPUT_DIR, xml_basename)\n",
        "with open(xml_path, \"w\") as f:\n",
        "    f.write(xml_used)\n",
        "print(\"💾 Saved BLAST XML:\", xml_path)\n",
        "\n",
        "# Expose for downstream cells\n",
        "BLAST_XML_PATH = xml_path\n",
        "BLAST_DB_USED = db_used"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DCZxRKFOCstM",
        "outputId": "627b18c1-a39b-4536-97ce-8c3c5807e2cf"
      },
      "id": "DCZxRKFOCstM",
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔎 Query: unknown_seq (len=1428 nt)\n",
            "⏳ Trying BLASTn vs refseq_rna  (megablast=True, E=1e-05)\n",
            "— No hits in refseq_rna (megablast=True)\n",
            "⏳ Trying BLASTn vs refseq_genomic  (megablast=True, E=1e-05)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/Bio/Blast/NCBIWWW.py:275: BiopythonWarning: BLAST request 9YS11FNB013 is taking longer than 10 minutes, consider re-issuing it\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZEggofJXMADJ"
      },
      "id": "ZEggofJXMADJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "42fa44d1",
      "metadata": {
        "id": "42fa44d1"
      },
      "source": [
        "\n",
        "## Cell 2 — Put your unknown DNA FASTA into DATA_DIR\n",
        "This cell verifies a FASTA is present and, if not, lets students upload directly into the right folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2cd941d3",
      "metadata": {
        "id": "2cd941d3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "60ea4bd6",
      "metadata": {
        "id": "60ea4bd6"
      },
      "source": [
        "\n",
        "## Cell 4 — (Optional) Quick visualization: identity distribution\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Quick plot of % identity for the top hits ---\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "df = pd.read_csv(csv_out)\n",
        "plt.figure()\n",
        "df[\"pct_identity\"].plot(kind=\"bar\")\n",
        "plt.title(\"% identity of BLASTn top hits\")\n",
        "plt.xlabel(\"Hit index\")\n",
        "plt.ylabel(\"% identity\")\n",
        "plt.tight_layout()\n",
        "\n",
        "png_path = f\"{OUTPUT_DIR}/blastn_identity_plot.png\"\n",
        "plt.savefig(png_path, dpi=150)\n",
        "print(\"💾 Saved plot:\", png_path)"
      ],
      "metadata": {
        "id": "9LXfeS7gu2ad"
      },
      "id": "9LXfeS7gu2ad",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "ce02bc34",
      "metadata": {
        "id": "ce02bc34"
      },
      "source": [
        "## Cell 5 — Canvas summary (simple key/value printout)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "596d0be0",
      "metadata": {
        "id": "596d0be0"
      },
      "outputs": [],
      "source": [
        "# --- Summary for Canvas auto-grading / quick check ---\n",
        "summary = {\n",
        "    \"LECTURE\": LECTURE_CODE,\n",
        "    \"TOPIC\": TOPIC,\n",
        "    \"QUERY_FASTA\": os.path.basename(FASTA_PATH),\n",
        "    \"HITS_FASTA\": os.path.basename(fasta_out),\n",
        "    \"HITS_CSV\": os.path.basename(csv_out)\n",
        "}\n",
        "print(\"=== L02 SUMMARY ===\")\n",
        "for k,v in summary.items():\n",
        "    print(f\"{k}={v}\")\n",
        "\n",
        "with open(f\"{OUTPUT_DIR}/summary.txt\",\"w\") as f:\n",
        "    for k,v in summary.items():\n",
        "        f.write(f\"{k}={v}\\n\")\n",
        "print(\"💾 Wrote\", f\"{OUTPUT_DIR}/summary.txt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now translate the sequence by running this code:"
      ],
      "metadata": {
        "id": "GB7VNxmNt2LU"
      },
      "id": "GB7VNxmNt2LU"
    },
    {
      "cell_type": "markdown",
      "id": "e7b1e8f5",
      "metadata": {
        "id": "e7b1e8f5"
      },
      "source": [
        "## E. Results summary (copy into Canvas if requested)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f1ff22f6",
      "metadata": {
        "id": "f1ff22f6"
      },
      "outputs": [],
      "source": [
        "\n",
        "summary_path = f\"{OUTPUT_DIR}/summary.txt\"\n",
        "with open(summary_path, \"w\") as f:\n",
        "    f.write(f\"LECTURE={LECTURE_CODE}\\n\")\n",
        "    f.write(f\"TOPIC={TOPIC}\\n\")\n",
        "    f.write(f\"N_records={len(records)}\\n\")\n",
        "    f.write(f\"FASTA={os.path.basename(fasta_path)}\\n\")\n",
        "print(\"📝 Saved summary ->\", summary_path)\n",
        "\n",
        "print(\"=== SUMMARY ===\")\n",
        "print(\"LECTURE=\", LECTURE_CODE)\n",
        "print(\"TOPIC=\", TOPIC)\n",
        "print(\"N_records=\", len(records))\n",
        "print(\"FASTA=\", os.path.basename(fasta_path))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "67332d7d",
      "metadata": {
        "id": "67332d7d"
      },
      "source": [
        "\n",
        "## F. Export & submit\n",
        "- **File → Print → Save as PDF**, then upload the PDF and `.ipynb` to Canvas.  \n",
        "- Ensure your `Outputs/` folder contains: `seq_summary.csv`, `lengths_barplot.png`, and `summary.txt`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8f21ad5f"
      },
      "source": [
        "%pip install biopython"
      ],
      "id": "8f21ad5f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fed93a7d"
      },
      "source": [
        "import os\n",
        "\n",
        "# Look for a DNA FASTA in DATA_DIR\n",
        "cands = [f for f in os.listdir(DATA_DIR) if f.lower().endswith((\".fa\",\".fasta\",\".fna\"))]\n",
        "\n",
        "# Use the newest FASTA\n",
        "cands.sort(key=lambda f: os.path.getmtime(f\"{DATA_DIR}/{f}\"), reverse=True)\n",
        "FASTA_PATH = f\"{DATA_DIR}/{cands[0]}\"\n",
        "print(\"📄 Using FASTA:\", FASTA_PATH)"
      ],
      "id": "fed93a7d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85fc88b7"
      },
      "source": [
        "from Bio.Blast import NCBIXML\n",
        "import io\n",
        "\n",
        "# Assuming blast_xml is available from a previous cell\n",
        "# If not, you would need to load it from the saved XML file\n",
        "# xml_path = f\"{OUTPUT_DIR}/blastn_refseqrna.xml\" # Or blastn_results.xml depending on which blast run you're using\n",
        "# with open(xml_path, \"r\") as f:\n",
        "#     blast_xml = f.read()\n",
        "\n",
        "record = NCBIXML.read(io.StringIO(blast_xml))\n",
        "assert record.alignments, \"No BLAST hits.\" # Add a check for alignments"
      ],
      "id": "85fc88b7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "775e3ccb"
      },
      "source": [
        "# --- BLASTn mini-API: find similar DNA and download top hits ---\n",
        "from Bio import Entrez, SeqIO\n",
        "from Bio.Blast import NCBIWWW, NCBIXML\n",
        "import os, csv, time\n",
        "\n",
        "# REQUIRED by NCBI: set your email (students: put YOUR email)\n",
        "Entrez.email = \"your_email@university.edu\"  # <-- change me\n",
        "API_KEY = None  # optional: paste NCBI API key to raise rate limits\n",
        "\n",
        "# Read first record as query\n",
        "rec = next(SeqIO.parse(FASTA_PATH, \"fasta\"))\n",
        "query_seq = str(rec.seq)\n",
        "print(f\"🔎 Query record: {rec.id} (len={len(rec)} nt)\")\n",
        "\n",
        "# Run BLASTn vs nt (fast & familiar for L02)\n",
        "print(\"⏳ Running BLASTn vs nt …\")\n",
        "blast_handle = NCBIWWW.qblast(\n",
        "    program=\"blastn\",\n",
        "    database=\"nt\",\n",
        "    sequence=query_seq,\n",
        "    expect=1e-5,\n",
        "    megablast=True,\n",
        "    filter=\"L\",                # low-complexity filter\n",
        "    entrez_query=None          # no organism filter in L02\n",
        ")\n",
        "blast_xml = blast_handle.read()\n",
        "blast_handle.close()\n",
        "\n",
        "# Save XML (reproducibility)\n",
        "xml_path = f\"{OUTPUT_DIR}/blastn_results.xml\"\n",
        "with open(xml_path, \"w\") as f:\n",
        "    f.write(blast_xml)\n",
        "print(\"💾 Saved BLAST XML:\", xml_path)"
      ],
      "id": "775e3ccb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Process XML to easy to read docs"
      ],
      "metadata": {
        "id": "PKgvxWnPECSz"
      },
      "id": "PKgvxWnPECSz"
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Summarize BLAST XML to a tidy table + CSV ---\n",
        "from Bio.Blast import NCBIXML\n",
        "import pandas as pd, os, io\n",
        "\n",
        "XML_PATH = \"/content/drive/MyDrive/Teaching/BIOINFO4-5203-F25/Outputs/L02_databases_formats_blastn_seed/blastn_results.xml\"\n",
        "assert os.path.exists(XML_PATH), \"XML file not found. Check the path.\"\n",
        "\n",
        "with open(XML_PATH) as f:\n",
        "    blast_record = NCBIXML.read(f)  # one query -> one record\n",
        "\n",
        "rows = []\n",
        "for aln in blast_record.alignments:\n",
        "    # take the first HSP per alignment for summary\n",
        "    h = aln.hsps[0]\n",
        "    rows.append({\n",
        "        \"accession\": aln.accession,\n",
        "        \"title\": aln.title,\n",
        "        \"length_nt\": aln.length,\n",
        "        \"bitscore\": h.bits,\n",
        "        \"evalue\": h.expect,\n",
        "        \"identities\": h.identities,\n",
        "        \"align_len\": h.align_length,\n",
        "        \"pct_identity\": round(100.0*h.identities/h.align_length, 2),\n",
        "        \"q_start\": h.query_start,\n",
        "        \"q_end\": h.query_end,\n",
        "        \"s_start\": h.sbjct_start,\n",
        "        \"s_end\": h.sbjct_end,\n",
        "        \"gaps\": h.gaps if hasattr(h, \"gaps\") else None\n",
        "    })\n",
        "\n",
        "df = pd.DataFrame(rows)\n",
        "df_sorted = df.sort_values([\"evalue\",\"bitscore\"], ascending=[True, False]).reset_index(drop=True)\n",
        "display(df_sorted.head(20))\n",
        "\n",
        "# Save CSV next to the XML\n",
        "CSV_OUT = os.path.join(os.path.dirname(XML_PATH), \"blastn_results_summary.csv\")\n",
        "df_sorted.to_csv(CSV_OUT, index=False)\n",
        "print(\"💾 Saved:\", CSV_OUT)"
      ],
      "metadata": {
        "id": "Ylvktw9KEI7y"
      },
      "id": "Ylvktw9KEI7y",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "filter to de-duplicate and save top hit only"
      ],
      "metadata": {
        "id": "yu5sXfNLFYrK"
      },
      "id": "yu5sXfNLFYrK"
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Export gene-level ORFs (CDS) for NR hits: mRNA -> CDS, genome -> overlap CDS ---\n",
        "from Bio.Blast import NCBIXML\n",
        "from Bio import Entrez, SeqIO\n",
        "from Bio.SeqFeature import SeqFeature, FeatureLocation\n",
        "import pandas as pd, os, io, time, json, re\n",
        "\n",
        "# REQUIRED by NCBI\n",
        "Entrez.email = \"your_email@university.edu\"   # <-- set this\n",
        "API_KEY = None  # optional\n",
        "\n",
        "# Inputs from earlier cells\n",
        "assert 'OUTPUT_DIR' in globals(), \"Set OUTPUT_DIR earlier.\"\n",
        "XML_PATH = xml_path if 'xml_path' in globals() else XML_PATH  # support either var name\n",
        "assert os.path.exists(XML_PATH), f\"Missing XML at: {XML_PATH}\"\n",
        "\n",
        "# Output paths\n",
        "CDS_NA_FASTA = os.path.join(OUTPUT_DIR, \"nr_hits_CDS_nucleotide.fasta\")\n",
        "CDS_AA_FASTA = os.path.join(OUTPUT_DIR, \"nr_hits_CDS_protein.fasta\")\n",
        "NR_SUMMARY   = os.path.join(OUTPUT_DIR, \"nr_hits_summary_genes.csv\")\n",
        "\n",
        "# 1) Parse BLAST XML and rank hits\n",
        "with open(XML_PATH) as f:\n",
        "    rec = NCBIXML.read(f)\n",
        "\n",
        "rows = []\n",
        "for aln in rec.alignments:\n",
        "    h = aln.hsps[0]\n",
        "    rows.append({\n",
        "        \"accession\": aln.accession,\n",
        "        \"title\": aln.title,\n",
        "        \"bitscore\": h.bits,\n",
        "        \"evalue\": h.expect,\n",
        "        \"pct_identity\": round(100.0*h.identities/h.align_length, 2),\n",
        "        \"align_len\": h.align_length,\n",
        "        \"s_start\": min(h.sbjct_start, h.sbjct_end),\n",
        "        \"s_end\":   max(h.sbjct_start, h.sbjct_end)\n",
        "    })\n",
        "df = pd.DataFrame(rows).sort_values(\n",
        "    [\"evalue\",\"bitscore\",\"pct_identity\",\"align_len\"],\n",
        "    ascending=[True, False, False, False]\n",
        ").reset_index(drop=True)\n",
        "\n",
        "# 2) De-duplicate by accession; optional: keep one per organism TaxID\n",
        "def esummary_json(db, ids):\n",
        "    params = dict(db=db, id=\",\".join(ids), retmode=\"json\")\n",
        "    if API_KEY: params[\"api_key\"] = API_KEY\n",
        "    with Entrez.esummary(**params) as h:\n",
        "        return json.load(h)\n",
        "\n",
        "df = df.drop_duplicates(subset=[\"accession\"], keep=\"first\").reset_index(drop=True)\n",
        "\n",
        "# Add TaxID/Organism/Biomol using ESummary (batched for speed)\n",
        "acc_list = df[\"accession\"].tolist()\n",
        "meta = esummary_json(\"nuccore\", acc_list)\n",
        "uid_map = {uid: meta[\"result\"][uid] for uid in meta[\"result\"][\"uids\"]}\n",
        "# ESummary may map accessions to UIDs; build acc->(taxid, organism, biomol, slen, title)\n",
        "def lookup_by_acc(acc):\n",
        "    # Find UID whose caption or extra matches acc\n",
        "    for uid, recj in uid_map.items():\n",
        "        if recj.get(\"caption\",\"\").startswith(acc) or recj.get(\"accessionversion\",\"\")==acc:\n",
        "            return {\n",
        "                \"uid\": uid,\n",
        "                \"taxid\": str(recj.get(\"taxid\",\"\")),\n",
        "                \"organism\": recj.get(\"organism\",\"\"),\n",
        "                \"biomol\": recj.get(\"biomol\",\"\"),        # \"mRNA\", \"genomic\", etc.\n",
        "                \"slen\": int(recj.get(\"slen\",0)),\n",
        "                \"esummary_title\": recj.get(\"title\",\"\")\n",
        "            }\n",
        "    # fallback\n",
        "    return {\"uid\":\"\", \"taxid\":\"\", \"organism\":\"\", \"biomol\":\"\", \"slen\":0, \"esummary_title\":\"\"}\n",
        "\n",
        "meta_rows = [lookup_by_acc(acc) for acc in acc_list]\n",
        "meta_df = pd.DataFrame(meta_rows)\n",
        "df = pd.concat([df, meta_df], axis=1)\n",
        "\n",
        "# Optional: keep one best per organism (TaxID) to promote diversity\n",
        "ENFORCE_ONE_PER_TAXON = True\n",
        "if ENFORCE_ONE_PER_TAXON:\n",
        "    df = df.sort_values([\"evalue\",\"bitscore\",\"pct_identity\",\"align_len\"],\n",
        "                        ascending=[True, False, False, False])\n",
        "    df = df.drop_duplicates(subset=[\"taxid\"], keep=\"first\").reset_index(drop=True)\n",
        "\n",
        "# 3) Helpers to fetch sequences\n",
        "def efetch_text(db, acc, rettype, **kw):\n",
        "    params = dict(db=db, id=acc, rettype=rettype, retmode=\"text\")\n",
        "    if API_KEY: params[\"api_key\"] = API_KEY\n",
        "    params.update(kw)\n",
        "    with Entrez.efetch(**params) as h:\n",
        "        return h.read()\n",
        "\n",
        "def fetch_genbank(acc):\n",
        "    txt = efetch_text(\"nuccore\", acc, \"gb\")\n",
        "    return SeqIO.read(io.StringIO(txt), \"genbank\")\n",
        "\n",
        "def fetch_cds_fastas(acc):\n",
        "    # For mRNA records, this typically yields one CDS sequence.\n",
        "    cds_na = efetch_text(\"nuccore\", acc, \"fasta_cds_na\")\n",
        "    cds_aa = efetch_text(\"nuccore\", acc, \"fasta_cds_aa\")\n",
        "    return cds_na, cds_aa\n",
        "\n",
        "# 4) Build CDS FASTAs (match the CDS overlapping the BLAST HSP when genomic)\n",
        "na_out = []\n",
        "aa_out = []\n",
        "summary_rows = []\n",
        "\n",
        "for _, r in df.iterrows():\n",
        "    acc = r[\"accession\"]\n",
        "    biomol = (r[\"biomol\"] or \"\").lower()\n",
        "    s_start, s_end = int(r[\"s_start\"]), int(r[\"s_end\"])\n",
        "\n",
        "    try:\n",
        "        if biomol == \"mrna\":\n",
        "            # Directly fetch CDS for mRNA (usually one coding sequence)\n",
        "            cds_na, cds_aa = fetch_cds_fastas(acc)\n",
        "            if cds_na.strip(): na_out.append(cds_na)\n",
        "            if cds_aa.strip(): aa_out.append(cds_aa)\n",
        "            used = \"mRNA_CDS\"\n",
        "        else:\n",
        "            # Genomic/chromosome: fetch GenBank and pick CDS overlapping HSP coords\n",
        "            gb = fetch_genbank(acc)\n",
        "            chosen = None\n",
        "            for feat in gb.features:\n",
        "                if feat.type != \"CDS\":\n",
        "                    continue\n",
        "                loc: FeatureLocation = feat.location\n",
        "                f_start = int(loc.start) + 1  # GenBank is 0-based; BLAST coords are 1-based\n",
        "                f_end   = int(loc.end)\n",
        "                # overlap test\n",
        "                if not (f_end < s_start or f_start > s_end):\n",
        "                    chosen = feat\n",
        "                    break\n",
        "            if chosen is None:\n",
        "                # Fallback: take the longest CDS (least-bad choice)\n",
        "                cds_feats = [f for f in gb.features if f.type==\"CDS\"]\n",
        "                chosen = max(cds_feats, key=lambda f: int(f.location.end)-int(f.location.start)) if cds_feats else None\n",
        "\n",
        "            if chosen is not None:\n",
        "                seq = chosen.extract(gb.seq)  # strand handled by Biopython\n",
        "                # Build headers\n",
        "                locus = chosen.qualifiers.get(\"locus_tag\", [\"\"])[0]\n",
        "                gene  = chosen.qualifiers.get(\"gene\", [\"\"])[0]\n",
        "                prod  = chosen.qualifiers.get(\"product\", [\"\"])[0]\n",
        "                prot  = chosen.qualifiers.get(\"protein_id\", [\"\"])[0]\n",
        "                hdr = f\">{acc}|CDS|locus={locus}|gene={gene}|prot={prot}|product={prod}\"\n",
        "                na_out.append(f\"{hdr}\\n{str(seq)}\\n\")\n",
        "                # Protein translation if available\n",
        "                transl = chosen.qualifiers.get(\"translation\", [\"\"])\n",
        "                if transl and transl[0]:\n",
        "                    aa_out.append(f\"{hdr}\\n{transl[0]}\\n\")\n",
        "                used = f\"genomic_CDS_overlap:{locus or gene or prot}\"\n",
        "            else:\n",
        "                used = \"no_CDS_found\"\n",
        "        summary_rows.append({\n",
        "            \"accession\": acc,\n",
        "            \"organism\": r.get(\"organism\",\"\"),\n",
        "            \"biomol\": r.get(\"biomol\",\"\"),\n",
        "            \"pct_identity\": r[\"pct_identity\"],\n",
        "            \"evalue\": r[\"evalue\"],\n",
        "            \"bitscore\": r[\"bitscore\"],\n",
        "            \"align_len\": r[\"align_len\"],\n",
        "            \"strategy\": used\n",
        "        })\n",
        "    except Exception as e:\n",
        "        summary_rows.append({\n",
        "            \"accession\": acc,\n",
        "            \"organism\": r.get(\"organism\",\"\"),\n",
        "            \"biomol\": r.get(\"biomol\",\"\"),\n",
        "            \"pct_identity\": r[\"pct_identity\"],\n",
        "            \"evalue\": r[\"evalue\"],\n",
        "            \"bitscore\": r[\"bitscore\"],\n",
        "            \"align_len\": r[\"align_len\"],\n",
        "            \"strategy\": f\"error:{e}\"\n",
        "        })\n",
        "    time.sleep(0.25 if not API_KEY else 0.1)\n",
        "\n",
        "# 5) Write outputs\n",
        "with open(CDS_NA_FASTA, \"w\") as f:\n",
        "    f.write(\"\".join(na_out))\n",
        "with open(CDS_AA_FASTA, \"w\") as f:\n",
        "    f.write(\"\".join(aa_out))\n",
        "pd.DataFrame(summary_rows).to_csv(NR_SUMMARY, index=False)\n",
        "\n",
        "print(\"✅ Wrote:\")\n",
        "print(\"  • CDS nucleotide FASTA :\", CDS_NA_FASTA)\n",
        "print(\"  • CDS protein FASTA    :\", CDS_AA_FASTA)\n",
        "print(\"  • NR gene summary CSV  :\", NR_SUMMARY)"
      ],
      "metadata": {
        "id": "bCVwa9qLFg_6"
      },
      "id": "bCVwa9qLFg_6",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}