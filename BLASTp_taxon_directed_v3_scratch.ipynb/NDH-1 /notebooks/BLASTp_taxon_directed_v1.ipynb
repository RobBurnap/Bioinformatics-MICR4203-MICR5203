{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RobBurnap/Bioinformatics-MICR4203-MICR5203/blob/main/BLASTp_taxon_directed_v3_scratch.ipynb/NDH-1%20/notebooks/BLASTp_taxon_directed_v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iqYMbqZH--Aw"
      },
      "source": [
        "#Cell 0: Mount Drive and define project folders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6M5JqM14YrrT"
      },
      "outputs": [],
      "source": [
        "!fusermount -u /content/drive 2>/dev/null || true\n",
        "!rm -rf /content/drive 2>/dev/null || true\n",
        "!mkdir -p /content/drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zLjESaNN-38W",
        "outputId": "d7f57070-be15-4460-d6ab-c0e800d049fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "PROJECT_ROOT: /content/drive/MyDrive/_Scratch/NDH1_BLASTp_taxon_directed\n",
            "DATA_DIR    : /content/drive/MyDrive/_Scratch/NDH1_BLASTp_taxon_directed/Data\n",
            "OUTPUT_DIR  : /content/drive/MyDrive/_Scratch/NDH1_BLASTp_taxon_directed/Outputs\n"
          ]
        }
      ],
      "source": [
        "# Cell 0: Mount Drive and define project folders\n",
        "# This notebook uses Google Drive as a *temporary scratch workspace*.\n",
        "# Put your inputs (query FASTA + taxid list) in:  DATA_DIR\n",
        "# Outputs will be written to:                   OUTPUT_DIR\n",
        "#\n",
        "# Recommended structure in Drive:\n",
        "#   MyDrive/_Scratch/NDH1_BLASTp_taxon_directed/\n",
        "#       Data/\n",
        "#       Outputs/\n",
        "\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# Mount Drive (safe to re-run; force_remount helps if you changed accounts)\n",
        "drive.mount('/content/drive', force_remount=False)\n",
        "\n",
        "# --- Scratch workspace (edit if you want a different folder name) ---\n",
        "PROJECT_ROOT = \"/content/drive/MyDrive/_Scratch/NDH1_BLASTp_taxon_directed\"\n",
        "\n",
        "DATA_DIR   = f\"{PROJECT_ROOT}/Data\"\n",
        "OUTPUT_DIR = f\"{PROJECT_ROOT}/Outputs\"\n",
        "\n",
        "# Create folders if they don't exist\n",
        "os.makedirs(DATA_DIR, exist_ok=True)\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "print(\"PROJECT_ROOT:\", PROJECT_ROOT)\n",
        "print(\"DATA_DIR    :\", DATA_DIR)\n",
        "print(\"OUTPUT_DIR  :\", OUTPUT_DIR)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rKMEQrln_LIf"
      },
      "source": [
        "##Cell 1:Install dependencies (BLAST+, Biopython, pandas)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8iFqRWKB_RxE",
        "outputId": "c2a552a8-9119-460b-8540-7a94adaf0d21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n"
          ]
        }
      ],
      "source": [
        "!apt-get update -qq\n",
        "!apt-get install -y ncbi-blast+ -qq\n",
        "\n",
        "!pip install biopython pandas -q\n",
        "!apt-get install -y ncbi-blast+ -qq\n",
        "!pip install biopython pandas requests -q"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fkYUXVP3_ivR"
      },
      "source": [
        "##Cell 2:Configuration: paths, NCBI email, input files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WnGXNwBo_kpQ",
        "outputId": "272dd650-d798-4703-8cc5-48d980c48524"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SUBUNIT           : NdhC\n",
            "Query FASTA       : /content/drive/MyDrive/_Scratch/NDH1_BLASTp_taxon_directed/Data/NdhC_Telong.fas\n",
            "TaxID List        : /content/drive/MyDrive/_Scratch/NDH1_BLASTp_taxon_directed/Data/ndh_project_taxids.txt\n",
            "Summary CSV       : /content/drive/MyDrive/_Scratch/NDH1_BLASTp_taxon_directed/Outputs/NdhC_top_hits_by_taxid2.csv\n",
            "Output FASTA      : /content/drive/MyDrive/_Scratch/NDH1_BLASTp_taxon_directed/Outputs/NdhC_top_hits_by_taxid2.faa\n"
          ]
        }
      ],
      "source": [
        "# Cell 2: Configuration (paths, email, input files)\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "from Bio import Entrez, SeqIO\n",
        "\n",
        "# REQUIRED by NCBI — use your real e-mail\n",
        "Entrez.email = \"rob.burnap@okstate.edu\"\n",
        "\n",
        "# ===== Choose the subunit you are working on =====\n",
        "# You will run the notebook one subunit at a time (simple + reproducible).\n",
        "SUBUNIT = \"NdhC\"   # e.g., \"NdhA\", \"NdhB\", \"NdhF\", ...\n",
        "\n",
        "# ===== INPUT FILES (place these in DATA_DIR) =====\n",
        "# Query FASTA should contain ONE protein sequence (the query).\n",
        "QUERY_FASTA = f\"{DATA_DIR}/{SUBUNIT}_Telong.fas\"\n",
        "\n",
        "# TaxID list is a 2-column, TAB-delimited file: Label <tab> TaxID\n",
        "# Example header line allowed:  Header<TAB>TaxID\n",
        "TAXID_LIST  = f\"{DATA_DIR}/ndh_project_taxids.txt\"\n",
        "\n",
        "# ===== OUTPUT FILES (written to OUTPUT_DIR) =====\n",
        "SUMMARY_CSV = f\"{OUTPUT_DIR}/{SUBUNIT}_top_hits_by_taxid2.csv\"\n",
        "MSA_FASTA   = f\"{OUTPUT_DIR}/{SUBUNIT}_top_hits_by_taxid2.faa\"\n",
        "\n",
        "print(\"SUBUNIT           :\", SUBUNIT)\n",
        "print(\"Query FASTA       :\", QUERY_FASTA)\n",
        "print(\"TaxID List        :\", TAXID_LIST)\n",
        "print(\"Summary CSV       :\", SUMMARY_CSV)\n",
        "print(\"Output FASTA      :\", MSA_FASTA)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6KBo1uRHGmD"
      },
      "source": [
        "#Cell 3: Load TaxID table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OGXj6wgzro4Y",
        "outputId": "205cc5e9-d160-4ebf-d2fa-d31c1dc642c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BLAST_PROGRAM : blastp\n",
            "BLAST_DB      : nr\n",
            "EVALUE        : 1e-05\n",
            "HITLIST_SIZE  : 10\n",
            "MAX_HSPS      : 1\n",
            "NCBI_SLEEP    : 2\n"
          ]
        }
      ],
      "source": [
        "# Cell 4: Set BLAST parameters (tune these if needed)\n",
        "\n",
        "# BLAST parameters\n",
        "BLAST_PROGRAM = \"blastp\"\n",
        "BLAST_DB = \"nr\"            # NCBI 'nr' via remote BLAST\n",
        "EVALUE = 1e-5\n",
        "HITLIST_SIZE = 10          # fetch a small list then take the best *usable* hit\n",
        "MAX_HSPS = 1\n",
        "\n",
        "# Courtesy delay between NCBI requests (seconds)\n",
        "NCBI_SLEEP = 2\n",
        "\n",
        "print(\"BLAST_PROGRAM :\", BLAST_PROGRAM)\n",
        "print(\"BLAST_DB      :\", BLAST_DB)\n",
        "print(\"EVALUE        :\", EVALUE)\n",
        "print(\"HITLIST_SIZE  :\", HITLIST_SIZE)\n",
        "print(\"MAX_HSPS      :\", MAX_HSPS)\n",
        "print(\"NCBI_SLEEP    :\", NCBI_SLEEP)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oRpA2kc_HLTW",
        "outputId": "ebd40b38-ec04-473e-f95e-3a7a0942cde7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 117 taxonomic labels/taxids.\n",
            "[('A1.Candidatus', '3018267'), ('A10.Thermoplasmatales', '261391'), ('A11.Cuniculiplasma', '1673428'), ('A12.Candidatus', '2608793'), ('A13.Thermoplasma', '1973142'), ('A14.Candidatus', '2026803'), ('A15.Thermoplasma', '273116'), ('A16.Thermoplasma', '50339'), ('A17.Candidatus', '3107143'), ('A18.Thermoplasmatales', '667138')]\n"
          ]
        }
      ],
      "source": [
        "# Cell 3: Load TaxID table (Header <tab> TaxID)\n",
        "\n",
        "import csv\n",
        "\n",
        "def load_taxids(taxid_file):\n",
        "    labels, taxids = [], []\n",
        "\n",
        "    with open(taxid_file, 'r') as fh:\n",
        "        reader = csv.reader(fh, delimiter='\\t')\n",
        "        for row in reader:\n",
        "            if len(row) < 2:\n",
        "                continue\n",
        "\n",
        "            label = row[0].strip()\n",
        "            taxid = row[1].strip()\n",
        "\n",
        "            # Skip header line\n",
        "            if label.lower() == \"header\" and taxid.lower() == \"taxid\":\n",
        "                continue\n",
        "\n",
        "            if not taxid.isdigit():\n",
        "                print(\"Skipping bad line:\", row)\n",
        "                continue\n",
        "\n",
        "            labels.append(label)\n",
        "            taxids.append(taxid)\n",
        "\n",
        "    return labels, taxids\n",
        "\n",
        "labels, taxids = load_taxids(TAXID_LIST)\n",
        "\n",
        "print(f\"Loaded {len(labels)} taxonomic labels/taxids.\")\n",
        "print(list(zip(labels, taxids))[:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ycYc4gdeIFCe"
      },
      "source": [
        "#Cell 4 — BLAST + Entrez helpers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "410e5f3c"
      },
      "outputs": [],
      "source": [
        "# Cell 4: BLAST + Entrez helper functions (upgraded for iTOL metadata)\n",
        "\n",
        "import time, re\n",
        "import requests\n",
        "from Bio import Entrez, SeqIO\n",
        "from Bio.Blast import NCBIWWW, NCBIXML\n",
        "\n",
        "def run_taxid_blastp(query_seq, taxid, hitlist_size=10, expect=1e-5):\n",
        "    \"\"\"\n",
        "    Remote blastp against nr restricted to a TaxID.\n",
        "    Returns (best_alignment, stats_dict) or (None, None)\n",
        "    \"\"\"\n",
        "    entrez_query = f\"txid{taxid}[ORGN]\"\n",
        "    handle = NCBIWWW.qblast(\n",
        "        program=\"blastp\",\n",
        "        database=\"nr\",\n",
        "        sequence=query_seq,\n",
        "        entrez_query=entrez_query,\n",
        "        hitlist_size=hitlist_size,\n",
        "        expect=expect,\n",
        "        format_type=\"XML\"\n",
        "    )\n",
        "    blast_record = NCBIXML.read(handle)\n",
        "    handle.close()\n",
        "\n",
        "    if not blast_record.alignments:\n",
        "        return None, None\n",
        "\n",
        "    align = blast_record.alignments[0]\n",
        "    hsp   = align.hsps[0]\n",
        "\n",
        "    stats = {\n",
        "        \"bitscore\": hsp.bits,\n",
        "        \"evalue\": hsp.expect,\n",
        "        \"identity\": hsp.identities,\n",
        "        \"align_length\": hsp.align_length,\n",
        "        \"pident\": 100*hsp.identities/max(1, hsp.align_length),\n",
        "        \"title\": align.title,\n",
        "    }\n",
        "    return align, stats\n",
        "\n",
        "def fetch_full_protein_fasta(accession):\n",
        "    handle = Entrez.efetch(db=\"protein\", id=accession, rettype=\"fasta\", retmode=\"text\")\n",
        "    records = list(SeqIO.parse(handle, \"fasta\"))\n",
        "    handle.close()\n",
        "    return records[0] if records else None\n",
        "\n",
        "def fetch_gb_record(accession):\n",
        "    \"\"\"\n",
        "    GenBank record is best for organism name and db_xref (taxon, UniProt).\n",
        "    \"\"\"\n",
        "    handle = Entrez.efetch(db=\"protein\", id=accession, rettype=\"gb\", retmode=\"text\")\n",
        "    rec = SeqIO.read(handle, \"genbank\")\n",
        "    handle.close()\n",
        "    return rec\n",
        "\n",
        "def parse_taxid_from_gb(gb_record):\n",
        "    \"\"\"\n",
        "    Extract taxid from source feature db_xref taxon:#### if present.\n",
        "    \"\"\"\n",
        "    for feat in gb_record.features:\n",
        "        if feat.type == \"source\":\n",
        "            for x in feat.qualifiers.get(\"db_xref\", []):\n",
        "                m = re.search(r\"taxon:(\\d+)\", x)\n",
        "                if m:\n",
        "                    return m.group(1)\n",
        "    return \"\"\n",
        "\n",
        "def parse_uniprot_from_gb(gb_record):\n",
        "    \"\"\"\n",
        "    Try to extract UniProt from CDS db_xref lines in the GenBank record.\n",
        "    Returns a ';'-joined string (possibly empty).\n",
        "    \"\"\"\n",
        "    hits = set()\n",
        "    for feat in gb_record.features:\n",
        "        if feat.type != \"CDS\":\n",
        "            continue\n",
        "        for x in feat.qualifiers.get(\"db_xref\", []):\n",
        "            m = re.search(r\"UniProtKB(?:/[^:]+)?:([A-Z0-9]{6,10})\", x)\n",
        "            if m:\n",
        "                hits.add(m.group(1))\n",
        "    return \";\".join(sorted(hits))\n",
        "\n",
        "def uniprot_map_refseq_to_uniprot(refseq_id, timeout=20):\n",
        "    \"\"\"\n",
        "    Fallback: map RefSeq protein (WP_/YP_/NP_) to UniProt using UniProt ID mapping API.\n",
        "    Returns UniProt accession or \"\".\n",
        "    \"\"\"\n",
        "    try:\n",
        "        submit = requests.post(\n",
        "            \"https://rest.uniprot.org/idmapping/run\",\n",
        "            data={\"from\": \"RefSeq_Protein\", \"to\": \"UniProtKB\", \"ids\": refseq_id},\n",
        "            timeout=timeout\n",
        "        )\n",
        "        submit.raise_for_status()\n",
        "        job = submit.json()[\"jobId\"]\n",
        "\n",
        "        # poll\n",
        "        for _ in range(30):\n",
        "            status = requests.get(f\"https://rest.uniprot.org/idmapping/status/{job}\", timeout=timeout)\n",
        "            status.raise_for_status()\n",
        "            js = status.json()\n",
        "            if js.get(\"jobStatus\") in (None, \"FINISHED\"):\n",
        "                break\n",
        "            time.sleep(1)\n",
        "\n",
        "        res = requests.get(\n",
        "            f\"https://rest.uniprot.org/idmapping/uniprotkb/results/{job}\",\n",
        "            params={\"format\": \"json\"},\n",
        "            timeout=timeout\n",
        "        )\n",
        "        res.raise_for_status()\n",
        "        data = res.json()\n",
        "        results = data.get(\"results\", [])\n",
        "        if results:\n",
        "            return results[0][\"to\"][\"primaryAccession\"]\n",
        "    except Exception:\n",
        "        return \"\"\n",
        "    return \"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FPIoqgDxIYW3"
      },
      "source": [
        "#Cell 5: Main loop: BLAST each TaxID, fetch sequence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fe46456d",
        "outputId": "adae8e25-e81a-42d1-bc2d-04e16c0cd471"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TaxID 3018267  (A1.Candidatus) ... hit: HVA22284\n",
            "TaxID 261391  (A10.Thermoplasmatales) ... hit: EQB67953\n",
            "TaxID 1673428  (A11.Cuniculiplasma) ... hit: WP_148690108\n",
            "TaxID 2608793  (A12.Candidatus) ... hit: CAD6492525\n",
            "TaxID 1973142  (A13.Thermoplasma) ... hit: WP_237265325\n",
            "TaxID 2026803  (A14.Candidatus) ... hit: MBS3164726\n",
            "TaxID 273116  (A15.Thermoplasma) ... hit: WP_241760266\n",
            "TaxID 50339  (A16.Thermoplasma) ... hit: WP_241760266\n",
            "TaxID 3107143  (A17.Candidatus) ... hit: MFQ6105625\n",
            "TaxID 667138  (A18.Thermoplasmatales) ... hit: EQB65936\n",
            "TaxID 2823368  (A19.Candidatus) ... hit: MBX8631139\n",
            "TaxID 2032688  (A2.Candidatus) ... hit: HEY9206500\n",
            "TaxID 1904752  (A20.Halobacteriales) ... hit: MFT4890955\n",
            "TaxID 3073602  (A21.Oxyplasma) ... hit: WP_393970915\n",
            "TaxID 2026795  (A22.Nitrososphaerota) ... hit: MGE5333765\n",
            "TaxID 1906667  (A23.Methanomassiliicoccales) ... hit: MDD1768528\n",
            "TaxID 1945595  (A24.Methanosarcinaceae) ... hit: MCD4702773\n",
            "TaxID 2026739  (A25.Methanobacteriota) ... hit: HDH28661\n",
            "TaxID 2026739  (A26.Methanobacteriota) ... hit: HDH28661\n",
            "TaxID 39669  (A27.Methanosalsum) ... hit: WP_013898875\n",
            "TaxID 2591003  (A28.Ferroplasma) ... hit: MEM0139640\n",
            "TaxID 1874737  (A29.Methanolobus) ... hit: MEZ5336228\n",
            "TaxID 2833567  (A3.Nitrosotalea) ... hit: HVB77553\n",
            "TaxID 2026739  (A4.Methanobacteriota) ... hit: HDH28661\n",
            "TaxID 1839936  (A5.Candidatus) ... hit: HDM37082\n",
            "TaxID 2365003  (A6.Candidatus) ... hit: RJS73609\n",
            "TaxID 2005738  (A7.archaeon) ... hit: GBE54681\n",
            "TaxID 1906666  (A8.Thermoplasmata) ... hit: MGB6501146\n",
            "TaxID 115547  (A9.uncultured) ... "
          ]
        }
      ],
      "source": [
        "# Cell 5: Main loop (BLAST per TaxID, fetch sequences + metadata, write iTOL files)\n",
        "\n",
        "import pandas as pd\n",
        "from Bio.SeqRecord import SeqRecord\n",
        "import os, time, re\n",
        "\n",
        "# Read the query sequence\n",
        "query_record = list(SeqIO.parse(QUERY_FASTA, \"fasta\"))[0]\n",
        "\n",
        "summary_rows = []\n",
        "seq_out = []\n",
        "\n",
        "# iTOL dataset outputs\n",
        "ITOL_LABELS = f\"{OUTPUT_DIR}/{SUBUNIT}_iTOL_LABELS.tsv\"\n",
        "ITOL_POPUP  = f\"{OUTPUT_DIR}/{SUBUNIT}_iTOL_POPUP.tsv\"\n",
        "\n",
        "# We'll build these as we go (keyed by NCBI accession)\n",
        "itol_labels_rows = []   # (acc, display_label)\n",
        "itol_popup_rows  = []   # (acc, popup_text)\n",
        "\n",
        "def make_display_label(label, organism, acc, taxid_requested):\n",
        "    \"\"\"\n",
        "    Choose what iTOL displays as the leaf label.\n",
        "    You can adjust formatting here freely.\n",
        "    \"\"\"\n",
        "    org = organism if organism else \"Unknown_organism\"\n",
        "    return f\"{org} | {acc} | {label} | txid:{taxid_requested}\"\n",
        "\n",
        "def make_popup_text(label, taxid_requested, acc, stats, organism, descr, taxid_hit, uniprot):\n",
        "    \"\"\"\n",
        "    iTOL popup: can be multi-line; keep it readable.\n",
        "    \"\"\"\n",
        "    lines = [\n",
        "        f\"Group label: {label}\",\n",
        "        f\"Requested TaxID: {taxid_requested}\",\n",
        "        f\"NCBI accession: {acc}\",\n",
        "        f\"Organism: {organism}\",\n",
        "        f\"Description: {descr}\",\n",
        "        f\"TaxID (from GenBank): {taxid_hit}\",\n",
        "        f\"UniProt: {uniprot}\",\n",
        "        \"\",\n",
        "        f\"BLAST bitscore: {stats.get('bitscore','')}\",\n",
        "        f\"BLAST evalue: {stats.get('evalue','')}\",\n",
        "        f\"BLAST %ident: {stats.get('pident',''):.2f}\" if isinstance(stats.get(\"pident\", None), (int,float)) else f\"BLAST %ident: {stats.get('pident','')}\",\n",
        "        f\"BLAST title: {stats.get('title','')}\",\n",
        "    ]\n",
        "    return \"\\n\".join(lines)\n",
        "\n",
        "# Run across list with real-time reporting\n",
        "for label, taxid in zip(labels, taxids):\n",
        "    print(f\"TaxID {taxid}  ({label}) ... \", end=\"\")\n",
        "\n",
        "    try:\n",
        "        align, stats = run_taxid_blastp(str(query_record.seq), taxid, hitlist_size=HITLIST_SIZE, expect=EVALUE)\n",
        "    except Exception as e:\n",
        "        print(\"BLAST error:\", e)\n",
        "        summary_rows.append({\n",
        "            \"label\": label,\n",
        "            \"taxid\": taxid,\n",
        "            \"status\": \"blast_error\",\n",
        "            \"error\": str(e)\n",
        "        })\n",
        "        time.sleep(NCBI_SLEEP)\n",
        "        continue\n",
        "\n",
        "    if align is None:\n",
        "        print(\"no hits\")\n",
        "        summary_rows.append({\n",
        "            \"label\": label,\n",
        "            \"taxid\": taxid,\n",
        "            \"status\": \"no_hits\"\n",
        "        })\n",
        "        time.sleep(NCBI_SLEEP)\n",
        "        continue\n",
        "\n",
        "    # Accession from Biopython alignment object (works well)\n",
        "    acc = align.accession\n",
        "    print(\"hit:\", acc)\n",
        "\n",
        "    # Fetch FASTA sequence\n",
        "    full = fetch_full_protein_fasta(acc)\n",
        "    if full is None:\n",
        "        print(\"  Failed to fetch sequence.\")\n",
        "        summary_rows.append({\n",
        "            \"label\": label,\n",
        "            \"taxid\": taxid,\n",
        "            \"ncbi_accession\": acc,\n",
        "            \"status\": \"fetch_fasta_failed\"\n",
        "        })\n",
        "        time.sleep(NCBI_SLEEP)\n",
        "        continue\n",
        "\n",
        "    # Fetch GenBank record for metadata\n",
        "    organism = \"\"\n",
        "    descr = \"\"\n",
        "    taxid_hit = \"\"\n",
        "    uniprot = \"\"\n",
        "\n",
        "    try:\n",
        "        gb = fetch_gb_record(acc)\n",
        "        organism = gb.annotations.get(\"organism\", \"\")\n",
        "        descr = gb.description\n",
        "        taxid_hit = parse_taxid_from_gb(gb)\n",
        "        uniprot = parse_uniprot_from_gb(gb)\n",
        "\n",
        "        # UniProt fallback mapping if missing and looks like RefSeq\n",
        "        if (not uniprot) and re.match(r\"^[A-Z]{2}_\\d+\", acc):\n",
        "            unip_fb = uniprot_map_refseq_to_uniprot(acc)\n",
        "            if unip_fb:\n",
        "                uniprot = unip_fb\n",
        "    except Exception as e:\n",
        "        # keep going; we still have the sequence + BLAST stats\n",
        "        print(f\"  (metadata warning: {type(e).__name__})\")\n",
        "\n",
        "    # Write FASTA with a rich header (kept for your records)\n",
        "    # IMPORTANT: iTOL/tree key should remain the accession, so we do NOT use this header as the ID.\n",
        "    # We'll store accession as the FASTA ID, and put details in description.\n",
        "    rich_desc = f\"{label}|taxid:{taxid}|org:{organism}|uniprot:{uniprot}\"\n",
        "    out_rec = SeqRecord(full.seq, id=acc, description=rich_desc)\n",
        "    seq_out.append(out_rec)\n",
        "\n",
        "    # Summary table row\n",
        "    summary_rows.append({\n",
        "        \"label\": label,\n",
        "        \"taxid\": taxid,\n",
        "        \"ncbi_accession\": acc,\n",
        "        \"taxid_hit\": taxid_hit,\n",
        "        \"organism\": organism,\n",
        "        \"description\": descr,\n",
        "        \"uniprot_accession\": uniprot,\n",
        "        **stats,\n",
        "        \"status\": \"hit\"\n",
        "    })\n",
        "\n",
        "    # iTOL datasets\n",
        "    display_label = make_display_label(label, organism, acc, taxid)\n",
        "    popup_text = make_popup_text(label, taxid, acc, stats, organism, descr, taxid_hit, uniprot)\n",
        "\n",
        "    itol_labels_rows.append((acc, display_label))\n",
        "    itol_popup_rows.append((acc, popup_text))\n",
        "\n",
        "    time.sleep(NCBI_SLEEP)\n",
        "\n",
        "# ---- Write outputs ----\n",
        "if seq_out:\n",
        "    SeqIO.write(seq_out, MSA_FASTA, \"fasta\")\n",
        "    print(\"FASTA saved to:\", MSA_FASTA)\n",
        "\n",
        "if summary_rows:\n",
        "    df = pd.DataFrame(summary_rows)\n",
        "    df.to_csv(SUMMARY_CSV, index=False)\n",
        "    print(\"Summary CSV saved to:\", SUMMARY_CSV)\n",
        "\n",
        "# ---- Write iTOL datasets (LABELS + POPUP) ----\n",
        "# LABELS format: https://itol.embl.de/help.cgi#labels\n",
        "if itol_labels_rows:\n",
        "    with open(ITOL_LABELS, \"w\") as f:\n",
        "        f.write(\"LABELS\\nSEPARATOR TAB\\nDATA\\n\")\n",
        "        for acc, lab in itol_labels_rows:\n",
        "            f.write(f\"{acc}\\t{lab}\\n\")\n",
        "    print(\"iTOL LABELS saved to:\", ITOL_LABELS)\n",
        "\n",
        "# POPUP format: https://itol.embl.de/help.cgi#popup\n",
        "if itol_popup_rows:\n",
        "    with open(ITOL_POPUP, \"w\") as f:\n",
        "        f.write(\"POPUP_INFO\\nSEPARATOR TAB\\nDATA\\n\")\n",
        "        for acc, text in itol_popup_rows:\n",
        "            # iTOL wants \\n escaped inside the popup field\n",
        "            safe = text.replace(\"\\t\", \" \").replace(\"\\n\", \"\\\\n\")\n",
        "            f.write(f\"{acc}\\t{safe}\\n\")\n",
        "    print(\"iTOL POPUP_INFO saved to:\", ITOL_POPUP)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zG8jrxYJ_rEX"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_i7df8yeNEps"
      },
      "outputs": [],
      "source": [
        "# Quick sanity check: confirm your input files are in DATA_DIR\n",
        "import os\n",
        "\n",
        "print(\"DATA_DIR exists?  \", os.path.isdir(DATA_DIR), DATA_DIR)\n",
        "print(\"QUERY_FASTA exists?\", os.path.exists(QUERY_FASTA), QUERY_FASTA)\n",
        "print(\"TAXID_LIST exists? \", os.path.exists(TAXID_LIST), TAXID_LIST)\n",
        "\n",
        "!ls -lah \"{DATA_DIR}\"\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}